{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <h1> [üß∂ –°–≤—è–∑–∫–∞ `Lightning` + `ClearML` –≤ CV. üñº](https://stepik.org/lesson/1500763/step/1?unit=1520877)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ –Ω–æ—É—Ç–±—É–∫–∞\n",
    "<img src='https://i.pinimg.com/originals/8b/1f/3b/8b1f3bc02301ab06c15fe48b84de4c48.gif' align=\"right\" width=\"508\" height=\"428\" >\n",
    "<br>\n",
    "\n",
    "<p><font size=\"3\" face=\"Arial\" font-size=\"large\"><ul type=\"square\">\n",
    "    \n",
    "<li><a href=\"#p2\">üé® –ó–∞–¥–∞—á–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</a></li>\n",
    "<li><a href=\"#p7\">üéõ –§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.</a></li>\n",
    "<li><a href=\"#p3\">üß∂ –°–≤—è–∑–∫–∞ –≤ –∑–∞–¥–∞—á–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ üß©</a></li>\n",
    "<li><a href=\"#p6\">üß∏ –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚úÖ </a></li>\n",
    "\n",
    "\n",
    "    \n",
    "</ul></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> üßë‚Äçüéì–†–∞–∑–±–µ—Ä–µ–º –∫–∞–∫ —Å–≤—è–∑–∫–∞ **PyTorch Lightning** c **ClearML** –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ CV-–∑–∞–¥–∞—á–∞—Ö. ü™Ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "–°–≤—è–∑–∫–∞ **ClearML** —Å **PyTorch Lightning** —Ç–∞–∫ –∂–µ –æ—Ç–ª–∏—á–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–µ–±—è –≤ –∑–∞–¥–∞—á–∞—Ö –∏–∑ CV-–¥–æ–º–µ–Ω–∞.\n",
    "\n",
    "* –£–¥–æ–±–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è —Å–µ—Ç–∫–∏, –æ—Å–æ–±–µ–Ω–Ω–æ, –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–∞ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Å–µ–≤—Ä–≤–µ—Ä–∞—Ö, –∞ –Ω–µ –≤ –Ω–æ—É—Ç–±—É–∫–∞—Ö.\n",
    "* –õ–µ–≥–∫–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–≥–æ –±—ç–∫–±–æ–Ω–∞\n",
    "* –î–∞–∂–µ –º–æ–∂–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (GAN –∏.—Ç.–ø)\n",
    "* –ü–ª—é—Å –≤—Å–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–ª–∏ –≤ –ø—Ä–æ—à–ª–æ–º —É—Ä–æ–∫–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <center> –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ –ø–æ–¥–≥—Ä—É–∑–∫–∞ –∫–ª—é—á–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install clearml tensorboard lightning torchvision torchmetrics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from lightning import LightningModule, Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "# –í–≤–µ–¥–∏—Ç–µ –ø–æ–æ—á–µ—Ä—ë–¥–Ω–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∫–ª—é—á–∏ –≤ –ø–æ—è–≤–∏–≤—à–µ–º—Å—è –æ–∫–Ω–µ (–∫–æ–¥ –∏–∑–º–µ–Ω—è—Ç—å –Ω–µ –Ω—É–∂–Ω–æ)\n",
    "# access_key = getpass(prompt=\"–í–≤–µ–¥–∏—Ç–µ API Access —Ç–æ–∫–µ–Ω: \")\n",
    "# secret_key = getpass(prompt=\"–í–≤–µ–¥–∏—Ç–µ API Secret —Ç–æ–∫–µ–Ω: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# #  –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ–∏ api-–∫–ª—é—á–∏\n",
    "# %env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "# %env CLEARML_API_HOST=https://api.clear.ml\n",
    "# %env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "\n",
    "# %env CLEARML_API_ACCESS_KEY=$access_key\n",
    "# %env CLEARML_API_SECRET_KEY=$secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=UR73VVAQC4EUA46EA09ZMIM08YT21P\n",
      "env: CLEARML_API_SECRET_KEY=ZC2NeA8YNAxcEfepGgjZ9RTI0yJNx1E24R3W3dqYx4P5LWTRFOWuwCQhHB2pSwCxMvg\n"
     ]
    }
   ],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=UR73VVAQC4EUA46EA09ZMIM08YT21P\n",
    "%env CLEARML_API_SECRET_KEY=ZC2NeA8YNAxcEfepGgjZ9RTI0yJNx1E24R3W3dqYx4P5LWTRFOWuwCQhHB2pSwCxMvg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> üé® –ó–∞–¥–∞—á–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "–ü–æ–¥–∫–ª—é—á–∞–µ–º –Ω–∞—à —Ä–æ–¥–Ω–æ–π –°learML –∏ —Å—Ä–∞–∑—É –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ –Ω–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=5bb19febe47c4d6dbf3345044a85514c\n",
      "2025-04-15 23:49:59,839 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/05a161c5d9a4441682554ceef036ed08/experiments/5bb19febe47c4d6dbf3345044a85514c/output/log\n"
     ]
    }
   ],
   "source": [
    "from clearml import Task\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ –≤ ClearML\n",
    "task = Task.init(\n",
    "    project_name=\"Image Classification\",\n",
    "    task_name=\"CIFAR10 Training with Image Logging\",\n",
    "    task_type=Task.TaskTypes.training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'num_epochs': 3, 'batch_size': 24, 'learning_rate': 0.001, 'dropout_rate': 0.25, 'num_images_to_log': 5}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"num_epochs\": 3,\n",
    "    \"batch_size\": 24,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"dropout_rate\": 0.25,\n",
    "    \"num_images_to_log\": 5,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "}\n",
    "config = task.connect(config)  # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ ClearML\n",
    "print(\"Hyperparameters:\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "–ù–∞–ø–∏—à–µ–º –∏ –æ–±—É—á–∏–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Å–µ—Ç–∫—É –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ `CIFAR10`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–ª–∞—Å—Å—ã CIFAR-10\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=2\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    test_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> üíÉ –ú–æ–¥–µ–ª—å (—Å–æ–±–µ—Ä—ë–º –ø—Ä–æ—Å—Ç—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏–∑ 2-—Ö Convolution —Å–ª–æ—ë–≤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Model(LightningModule):\n",
    "    def __init__(self, num_classes=10, dropout_rate=0.25, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 6 * 6, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes, top_k=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n",
    "        task.get_logger().report_scalar(\"Loss\", \"train\", loss.item(), self.global_step)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        acc = self.accuracy(outputs, labels)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, on_step=False, on_epoch=True)\n",
    "        task.get_logger().report_scalar(\"Loss\", \"val\", loss.item(), self.global_step)\n",
    "        task.get_logger().report_scalar(\"Accuracy\", \"val\", acc.item(), self.global_step)\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "        if batch_idx == 0:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞\n",
    "            _, predicted = outputs.max(1)\n",
    "            for i in range(min(len(inputs), config[\"num_images_to_log\"])):\n",
    "                img = transforms.ToPILImage()(inputs[i].cpu())\n",
    "                pred_label = predicted[i].item()\n",
    "                true_label = labels[i].item()\n",
    "                title = f\"True: {classes[true_label]}, Pred: {classes[pred_label]}\"\n",
    "                # –ë–µ—Ä—ë–º –ª–æ–≥–≥–µ—Ä –∏–∑ ClearML –∏ –µ–≥–æ –º–µ—Ç–æ–¥ report_image()\n",
    "                task.get_logger().report_image(\n",
    "                    title=title,\n",
    "                    series=f\"Batch {self.current_epoch}\",\n",
    "                    iteration=self.global_step,\n",
    "                    image=img,\n",
    "                )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.SGD(self.parameters(), lr=self.hparams.learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Ç—Ä–µ–Ω–µ—Ä–∞ üí™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\n",
    "callbacks = [\n",
    "    ModelCheckpoint(monitor=\"val_acc\", mode=\"max\", save_top_k=1),\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=config[\"num_epochs\"],\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=\"auto\",\n",
    "    callbacks=callbacks,\n",
    "    log_every_n_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name     | Type               | Params | Mode \n",
      "--------------------------------------------------------\n",
      "0 | model    | Sequential         | 81.3 K | train\n",
      "1 | loss_fn  | CrossEntropyLoss   | 0      | train\n",
      "2 | accuracy | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------\n",
      "81.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "81.3 K    Total params\n",
      "0.325     Total estimated model params size (MB)\n",
      "16        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42327c1fcac7407cbc0888abeed3d084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bb00f2bbd64afaaa53bf2f9ee3b297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9d6c7e80bf40178b3512bb2d6acb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1062062448904a69b8e9d1ffa92d9c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6674401c1b6646418c346d62ea3521d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "model = CIFAR10Model(\n",
    "    dropout_rate=config[\"dropout_rate\"], learning_rate=config[\"learning_rate\"]\n",
    ")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–µ –∑–∞–±—ã–≤–∞–µ–º –∑–∞–∫—Ä—ã—Ç—å —Ç–∞—Å–∫\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://app.clear.ml/projects/05a161c5d9a4441682554ceef036ed08/experiments/5bb19febe47c4d6dbf3345044a85514c/output/log'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.get_output_log_web_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "* –ï—Å–ª–∏ –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ –≤–∫–ª–∞–¥–∫—É `DEBUG SAMPLES` —ç–∫—Å–ø–µ—Ä–º–µ–Ω—Ç–∞ —É–≤–∏–¥–∏–º, —á—Ç–æ —Å –ø—Ä–æ—Å—Ç–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –º–æ–¥–µ–ª—å —Å–æ–≤—Å–µ–º –ø–ª–æ—Ö–æ –Ω–∞—É—á–∏–ª–∞—Å—å –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –∫–ª–∞—Å—Å—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "  \n",
    "<img src='../images/cifnet.png' align=\"center\" height=\"428\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> üéõ –§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "  \n",
    "* –î–∞–ª–µ–µ –ø–æ–ø—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π –±—ç–∫–±–æ–Ω `ResNet18`\n",
    "* –ó–∞–æ–¥–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–∏–º –∫–∞–∫ –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `Transfer Learning` –Ω–∞ `Lightning`!\n",
    "* –°–ø–µ—Ä–≤–∞ –≤—Å–µ —Ç–∞–∫ –∂–µ –¥–µ–ª–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –∫–æ–Ω—Ñ–∏–≥–∞ **ClearML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=34790ff7ccbc492783af2998217e1d6d\n",
      "ClearML results page: https://app.clear.ml/projects/05a161c5d9a4441682554ceef036ed08/experiments/34790ff7ccbc492783af2998217e1d6d/output/log\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "from clearml import Task\n",
    "\n",
    "# ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ClearML Task\n",
    "task = Task.init(\n",
    "    project_name=\"Image Classification\",\n",
    "    task_name=\"Fine-tuning ResNet18 on CIFAR10\",\n",
    "    task_type=Task.TaskTypes.training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'num_epochs': 10, 'batch_size': 32, 'learning_rate': 0.001, 'fine_tune_start_epoch': 5, 'num_classes': 10, 'num_images_to_log': 5}\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "config = {\n",
    "    \"num_epochs\": 10,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"fine_tune_start_epoch\": 5,  # –° –∫–∞–∫–æ–π —ç–ø–æ—Ö–∏ —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞—Ç—å –±—ç–∫–±–æ–Ω\n",
    "    \"num_classes\": 10,\n",
    "    \"num_images_to_log\": 5,  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ ClearML\n",
    "}\n",
    "config = task.connect(config)\n",
    "print(\"Hyperparameters:\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> ü§∞ –ú–æ–¥–µ–ª—å (–≤–æ–∑—å–º—ë–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π –±—ç–∫–±–æ–Ω ResNet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**üîπ –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Fine-Tuning?**\n",
    "* –í –ø–µ—Ä–≤—ã–µ `fine_tune_start_epoch` —ç–ø–æ—Ö–∏ —Ç—Ä–µ–Ω–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π (fc).\n",
    "* –ó–∞—Ç–µ–º —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç—Å—è –≤–µ—Å—å `ResNet18` –∏ –æ–±—É—á–∞–µ—Ç—Å—è –≤—Å—è –º–æ–¥–µ–ª—å.\n",
    "* üî• –≠—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –≤ `Transfer Learning`, –∫–æ—Ç–æ—Ä—ã–π –¥–µ–ª–∞–µ—Ç `fine-tuning` —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Lightning-–º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ResNet18\n",
    "class FineTuneResNet(LightningModule):\n",
    "    def __init__(self, num_classes=10, learning_rate=1e-3, fine_tune_start_epoch=5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π ResNet18\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "\n",
    "        # –ó–∞–º–µ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –Ω–∞ 10 –∫–ª–∞—Å—Å–æ–≤ (CIFAR-10)\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤–µ—Å–∞ –±—ç–∫–±–æ–Ω–∞ (–∫—Ä–æ–º–µ fc)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ ClearML\n",
    "        task.get_logger().report_scalar(\"Loss\", \"train\", loss.item(), self.global_step)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        acc = (outputs.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True)\n",
    "\n",
    "        task.get_logger().report_scalar(\"Loss\", \"val\", loss.item(), self.global_step)\n",
    "        task.get_logger().report_scalar(\"Accuracy\", \"val\", acc.item(), self.global_step)\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ ClearML\n",
    "        if batch_idx == 0:\n",
    "            _, predicted = outputs.max(1)\n",
    "            for i in range(min(len(inputs), config[\"num_images_to_log\"])):\n",
    "                img = transforms.ToPILImage()(inputs[i].cpu())\n",
    "                pred_label = predicted[i].item()\n",
    "                true_label = labels[i].item()\n",
    "                title = f\"True: {classes[true_label]}, Pred: {classes[pred_label]}\"\n",
    "                task.get_logger().report_image(\n",
    "                    title=title,\n",
    "                    series=f\"Epoch {self.current_epoch}\",\n",
    "                    iteration=self.global_step,\n",
    "                    image=img,\n",
    "                )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.model.fc.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def on_epoch_start(self):\n",
    "        # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –±—ç–∫–±–æ–Ω –ø–æ—Å–ª–µ N-–π —ç–ø–æ—Ö–∏\n",
    "        if self.current_epoch >= self.hparams.fine_tune_start_epoch:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = True\n",
    "            print(f\"üîì –†–∞–∑–º–æ—Ä–æ–∑–∫–∞ –≤—Å–µ—Ö —Å–ª–æ–µ–≤ –º–æ–¥–µ–ª–∏ –Ω–∞ {self.current_epoch}-–π —ç–ø–æ—Ö–µ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**üîπ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç –∫–æ–¥?**\n",
    "1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é `ResNet18` –∏–∑ `torchvision.models`\n",
    "2. –ú–µ–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –Ω–∞ 10 –∫–ª–∞—Å—Å–æ–≤ (CIFAR-10)\n",
    "3. –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç –≤–µ—Å–∞ –±—ç–∫–±–æ–Ω–∞ (–ø–µ—Ä–≤—ã–µ `fine_tune_start_epoch` —ç–ø–æ—Ö)\n",
    "4. –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç –≤—Å—é –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ `fine_tune_start_epoch`\n",
    "5. –õ–æ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ `ClearML`\n",
    "6. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ `val_acc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**üîπ –ß—Ç–æ –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è –≤ ClearML?**\n",
    "\n",
    "- ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ (`train_loss`, `val_loss`, `val_acc`)\n",
    "- ‚úÖ –û—Ç–ª–∞–¥–æ—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏\n",
    "- ‚úÖ –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "- ‚úÖ –ú–æ–¥–µ–ª—å —Å –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinarian/venvs/sinara/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning:\n",
      "\n",
      "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "\n",
      "/home/sinarian/venvs/sinara/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning:\n",
      "\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FineTuneResNet(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FineTuneResNet(\n",
    "    num_classes=config[\"num_classes\"],\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    fine_tune_start_epoch=config[\"fine_tune_start_epoch\"],\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(monitor=\"val_acc\", mode=\"max\", save_top_k=1),\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | ResNet           | 11.2 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e1261ba0534035bfb44fd96e910903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0ec652f05e426586154bb5c890d9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3365c995a6f7447a9ff70fc892d23113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7dcd65032c4a9ca4f60b52c669f3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4db935150046d0969bd8cc99e93ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40434c5ff5d141b2811b3adf94196bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455b5ff768144fe9a31ddcf561721c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5274d15f492a44179502d128197e4e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c792aa32a22849f9ae51f5b97d68ec1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526acce32e67425c96d163db48b83425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff419e96ce194cf399fd97add49860fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5336d9f4c22e4f46a5da54b6a0d18cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å\n",
    "trainer = Trainer(\n",
    "    max_epochs=config[\"num_epochs\"],\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=\"auto\",\n",
    "    callbacks=callbacks,\n",
    "    log_every_n_steps=50,\n",
    ")\n",
    "\n",
    "# ‚úÖ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://app.clear.ml/projects/05a161c5d9a4441682554ceef036ed08/experiments/34790ff7ccbc492783af2998217e1d6d/output/log'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.get_output_log_web_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> üëÄ –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "* –í–∏–¥–Ω–æ –∫–∞–∫ –º–æ–¥–µ–ª—å –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ \"—É–º–Ω–µ–µ—Ç\" - –ø–µ—Ä–µ—Å—Ç–∞—ë—Ç –æ—à–∏–±–∞—Ç—å—Å—è –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∫–ª–∞—Å—Å–æ–≤.\n",
    "* –°–Ω–∞—á–∞–ª–∞ –æ—à–∏–±–∞–µ—Ç—Å—è –≤–æ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–∞—Ö, –ø–æ—Ç–æ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç `cat` –∏ `ship`\n",
    "\n",
    "<img src='../images/cif10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> üß∂ –°–≤—è–∑–∫–∞ –≤ –∑–∞–¥–∞—á–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ üß©</center>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "–†–∞–∑–±–µ—Ä—ë–º –ø—Ä–∏–º–µ—Ä —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º `PyTorch Lightning` –∏ `ClearML`. –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å `FCN-ResNet50` –∏–∑ `torchvision.models.segmentation` –∏ –æ–±—É—á–∞—Ç—å –µ—ë –Ω–∞ `VOC Segmentation Dataset (Pascal VOC 2012)`.\n",
    "\n",
    "`VOC Segmentation Dataset (Pascal VOC 2012)` - —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ–±—ä–µ–∫—Ç–∞–º–∏ 20 –∫–ª–∞—Å—Å–æ–≤ –∏ 1 —Ñ–æ–Ω–æ–≤—ã–π –∫–ª–∞—Å—Å.\n",
    "\n",
    "–¢–∞–∫ –∂–µ –∏–∑ `torchmetrics` –≤–æ–∑—å–º—ë–º `JaccardIndex` –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏ `IoU`.\n",
    "\n",
    "–í –∏—Ç–æ–≥–µ –ø–æ–ª—É—á–∏—Ç—Å—è —Å–∏–ª—å–Ω–∞—è —Å–≤—è–∑–∫–∞: **‚ö° Lightning + ClearML + torchmetrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=77ae83b4fb1d41f7bfc71221fc8c2830\n",
      "ClearML results page: https://app.clear.ml/projects/3f6029130fe24501a93383579483c1df/experiments/77ae83b4fb1d41f7bfc71221fc8c2830/output/log\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ –≤ ClearML\n",
    "task = Task.init(\n",
    "    project_name=\"VOC-Segmentation\",\n",
    "    task_name=\"Fine-Tuning FCN-ResNet50-VOC\",\n",
    "    task_type=Task.TaskTypes.training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'dataset': 'VOC2012', 'data_root': './data', 'image_size': (520, 520), 'batch_size': 8, 'num_workers': 4, 'model_name': 'fcn_resnet50', 'pretrained': True, 'num_classes': 21, 'learning_rate': 0.001, 'num_epochs': 10, 'optimizer': 'Adam', 'scheduler': 'ReduceLROnPlateau', 'scheduler_params': {'mode': 'min', 'factor': 0.5, 'patience': 2}, 'image_normalization': {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, 'device': 'gpu'}\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "config = {\n",
    "    # Data parameters\n",
    "    \"dataset\": \"VOC2012\",\n",
    "    \"data_root\": \"./data\",\n",
    "    \"image_size\": (520, 520),\n",
    "    \"batch_size\": 8,\n",
    "    \"num_workers\": 4,\n",
    "    # Model parameters\n",
    "    \"model_name\": \"fcn_resnet50\",\n",
    "    \"pretrained\": True,\n",
    "    \"num_classes\": 21,  # VOC has 20 classes + background\n",
    "    # Training parameters\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 10,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"scheduler_params\": {\"mode\": \"min\", \"factor\": 0.5, \"patience\": 2},\n",
    "    # Transforms\n",
    "    \"image_normalization\": {\n",
    "        \"mean\": [0.485, 0.456, 0.406],\n",
    "        \"std\": [0.229, 0.224, 0.225],\n",
    "    },\n",
    "    # Hardware\n",
    "    \"device\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "}\n",
    "config = task.connect(config)\n",
    "print(\"Hyperparameters:\", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö (Pascal VOC 2012)\n",
    "def get_dataloaders(batch_size):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=config[\"image_normalization\"][\"mean\"],\n",
    "                std=config[\"image_normalization\"][\"std\"],\n",
    "            ),\n",
    "            transforms.Resize(config[\"image_size\"], antialias=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    target_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.PILToTensor(),\n",
    "            transforms.Resize(\n",
    "                config[\"image_size\"], interpolation=transforms.InterpolationMode.NEAREST\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_dataset = datasets.VOCSegmentation(\n",
    "        root=config[\"data_root\"],\n",
    "        year=\"2012\",\n",
    "        image_set=\"train\",\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "        target_transform=target_transform,\n",
    "    )\n",
    "    val_dataset = datasets.VOCSegmentation(\n",
    "        root=config[\"data_root\"],\n",
    "        year=\"2012\",\n",
    "        image_set=\"val\",\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "        target_transform=target_transform,\n",
    "    )\n",
    "\n",
    "    # Log dataset information\n",
    "    task.get_logger().report_text(\n",
    "        f\"Train dataset size: {len(train_dataset)} samples\", level=logging.INFO\n",
    "    )\n",
    "    task.get_logger().report_text(\n",
    "        f\"Validation dataset size: {len(val_dataset)} samples\", level=logging.INFO\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config[\"num_workers\"],\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config[\"num_workers\"],\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported key of type '<class 'int'>' found when connecting dictionary. It will be converted to str\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_mapping': {0: 'background',\n",
       "  1: 'aeroplane',\n",
       "  2: 'bicycle',\n",
       "  3: 'bird',\n",
       "  4: 'boat',\n",
       "  5: 'bottle',\n",
       "  6: 'bus',\n",
       "  7: 'car',\n",
       "  8: 'cat',\n",
       "  9: 'chair',\n",
       "  10: 'cow',\n",
       "  11: 'diningtable',\n",
       "  12: 'dog',\n",
       "  13: 'horse',\n",
       "  14: 'motorbike',\n",
       "  15: 'person',\n",
       "  16: 'pottedplant',\n",
       "  17: 'sheep',\n",
       "  18: 'sofa',\n",
       "  19: 'train',\n",
       "  20: 'tvmonitor'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ù–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ VOC\n",
    "voc_class_names = [\n",
    "    \"background\",\n",
    "    \"aeroplane\",\n",
    "    \"bicycle\",\n",
    "    \"bird\",\n",
    "    \"boat\",\n",
    "    \"bottle\",\n",
    "    \"bus\",\n",
    "    \"car\",\n",
    "    \"cat\",\n",
    "    \"chair\",\n",
    "    \"cow\",\n",
    "    \"diningtable\",\n",
    "    \"dog\",\n",
    "    \"horse\",\n",
    "    \"motorbike\",\n",
    "    \"person\",\n",
    "    \"pottedplant\",\n",
    "    \"sheep\",\n",
    "    \"sofa\",\n",
    "    \"train\",\n",
    "    \"tvmonitor\",\n",
    "]\n",
    "# –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤\n",
    "task.connect({\"class_mapping\": {i: name for i, name in enumerate(voc_class_names)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforms: {'image_transforms': ['ToTensor()', 'Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])', 'Resize(size=(520, 520), antialias=True)'], 'target_transforms': ['PILToTensor()', 'Resize(size=(520, 520), interpolation=InterpolationMode.NEAREST)']}\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ –ó–∞–ª–æ–≥–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "transforms_config = {\n",
    "    \"image_transforms\": [\n",
    "        \"ToTensor()\",\n",
    "        f\"Normalize(mean={config['image_normalization']['mean']}, std={config['image_normalization']['std']})\",\n",
    "        f\"Resize(size={config['image_size']}, antialias=True)\",\n",
    "    ],\n",
    "    \"target_transforms\": [\n",
    "        \"PILToTensor()\",\n",
    "        f\"Resize(size={config['image_size']}, interpolation=InterpolationMode.NEAREST)\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Log configuration to ClearML\n",
    "task.connect_configuration({\"transforms_config\": transforms_config})\n",
    "print(\"Transforms:\", transforms_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ –ú–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º FCN-ResNet50\n",
    "import torchmetrics\n",
    "from PIL import Image\n",
    "from torchvision.models.segmentation import FCN_ResNet50_Weights, fcn_resnet50\n",
    "\n",
    "\n",
    "class SegmentationModel(LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.num_classes = config[\"num_classes\"]\n",
    "        self.lr = config[\"learning_rate\"]\n",
    "\n",
    "        # –ö–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–∏\n",
    "        self.model_config = {\n",
    "            \"backbone\": \"resnet50\",\n",
    "            \"head\": \"FCN\",\n",
    "            \"pretrained\": config[\"pretrained\"],\n",
    "            \"num_classes\": self.num_classes,\n",
    "        }\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º pretrained FCN-ResNet50\n",
    "        if config[\"pretrained\"]:\n",
    "            self.model = fcn_resnet50(weights=FCN_ResNet50_Weights.DEFAULT)\n",
    "        else:\n",
    "            self.model = fcn_resnet50(weights=None)\n",
    "\n",
    "        self.model.classifier[4] = nn.Conv2d(\n",
    "            512, self.num_classes, kernel_size=(1, 1), stride=(1, 1)\n",
    "        )\n",
    "\n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "        self.train_iou = torchmetrics.JaccardIndex(\n",
    "            task=\"multiclass\", num_classes=self.num_classes, ignore_index=255\n",
    "        )\n",
    "        self.val_iou = torchmetrics.JaccardIndex(\n",
    "            task=\"multiclass\", num_classes=self.num_classes, ignore_index=255\n",
    "        )\n",
    "\n",
    "        # –ú–µ—Ç—Ä–∏–∫–∞ IoU\n",
    "        self.val_class_iou = torchmetrics.JaccardIndex(\n",
    "            task=\"multiclass\",\n",
    "            num_classes=self.num_classes,\n",
    "            average=None,\n",
    "            ignore_index=255,\n",
    "        )\n",
    "\n",
    "        # ClearML logger\n",
    "        self.clearml_logger = task.get_logger()\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏\n",
    "        self.clearml_logger.report_text(\n",
    "            f\"Model Architecture: {self.model_config}\", level=logging.INFO\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)[\"out\"]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        masks = masks.squeeze(1).long()  # Convert [B, 1, H, W] to [B, H, W]\n",
    "\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, masks, ignore_index=255)\n",
    "\n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º IoU\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        iou = self.train_iou(preds, masks)\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ ClearML\n",
    "        self.clearml_logger.report_scalar(\n",
    "            \"Train/Loss\", \"CE\", loss.item(), self.global_step\n",
    "        )\n",
    "        self.clearml_logger.report_scalar(\n",
    "            \"Train/IoU\", \"Mean\", iou.item(), self.global_step\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        masks = masks.squeeze(1).long()\n",
    "\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, masks, ignore_index=255)\n",
    "\n",
    "        # –í—ã—á–º—Å–ª—è–µ–º IoU\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        iou = self.val_iou(preds, masks)\n",
    "\n",
    "        # Calculate per-class IoU\n",
    "        self.val_class_iou(preds, masks)\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å—ç–º–ø–ª—ã\n",
    "        if batch_idx == 0:\n",
    "            self._log_images(images, masks, preds)\n",
    "\n",
    "        result = {\"val_loss\": loss, \"val_iou\": iou}\n",
    "        self.validation_step_outputs.append(result)\n",
    "        return result\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        outputs = self.validation_step_outputs\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_iou = self.val_iou.compute()\n",
    "\n",
    "        # –ü–æ–ª—É—á–∞–µ–º IoU –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏ –ª–æ–≥–∏—Ä—É–µ–º\n",
    "        class_ious = self.val_class_iou.compute()\n",
    "        for i, class_iou in enumerate(class_ious):\n",
    "            self.clearml_logger.report_scalar(\n",
    "                f\"Val/ClassIoU\",\n",
    "                voc_class_names[i],\n",
    "                class_iou.item(),\n",
    "                self.current_epoch,\n",
    "            )\n",
    "\n",
    "        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —ç–ø–æ—Ö–∏\n",
    "        self.val_iou.reset()\n",
    "        self.val_class_iou.reset()\n",
    "\n",
    "        self.clearml_logger.report_scalar(\n",
    "            \"Val/Loss\", \"CE\", avg_loss.item(), self.current_epoch\n",
    "        )\n",
    "        self.clearml_logger.report_scalar(\n",
    "            \"Val/IoU\", \"Mean\", avg_iou.item(), self.current_epoch\n",
    "        )\n",
    "\n",
    "        self.log(\"val_loss\", avg_loss, prog_bar=True)\n",
    "        self.log(\"val_iou\", avg_iou, prog_bar=True)\n",
    "\n",
    "    def _log_images(self, images, masks, predictions, max_imgs=4):\n",
    "        \"\"\"Log images with ClearML for visualization\"\"\"\n",
    "        n_imgs = min(max_imgs, images.shape[0])\n",
    "\n",
    "        # –°–æ–∑–¥–∞—ë–º colormap –¥–ª—è –º–∞—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "        def colorize_mask(mask):\n",
    "            cmap = plt.get_cmap(\"tab20\", self.num_classes)\n",
    "            colored = cmap(mask.cpu().numpy())\n",
    "            return Image.fromarray((colored[:, :, :3] * 255).astype(np.uint8))\n",
    "\n",
    "        for idx in range(n_imgs):\n",
    "            # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
    "            img = images[idx].cpu().permute(1, 2, 0).numpy()\n",
    "            img = np.clip(\n",
    "                (\n",
    "                    img * np.array(self.config[\"image_normalization\"][\"std\"])\n",
    "                    + np.array(self.config[\"image_normalization\"][\"mean\"])\n",
    "                ),\n",
    "                0,\n",
    "                1,\n",
    "            )\n",
    "            img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "\n",
    "            # Ground truth –º–∞—Å–∫–∞\n",
    "            gt_mask = colorize_mask(masks[idx])\n",
    "\n",
    "            # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–∞—Å–∫–∞\n",
    "            pred_mask = colorize_mask(predictions[idx])\n",
    "\n",
    "            self.clearml_logger.report_image(\n",
    "                title=\"Validation Images\",\n",
    "                series=\"Input Image\",\n",
    "                iteration=self.global_step,\n",
    "                image=img,\n",
    "            )\n",
    "            self.clearml_logger.report_image(\n",
    "                title=\"Validation Images\",\n",
    "                series=\"GT Mask\",\n",
    "                iteration=self.global_step,\n",
    "                image=gt_mask,\n",
    "            )\n",
    "            self.clearml_logger.report_image(\n",
    "                title=\"Validation Images\",\n",
    "                series=\"Predicted Mask\",\n",
    "                iteration=self.global_step,\n",
    "                image=pred_mask,\n",
    "            )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        if self.config[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=self.config[\"scheduler_params\"][\"mode\"],\n",
    "                factor=self.config[\"scheduler_params\"][\"factor\"],\n",
    "                patience=self.config[\"scheduler_params\"][\"patience\"],\n",
    "                verbose=True,\n",
    "            )\n",
    "            return {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_scheduler\": {\n",
    "                    \"scheduler\": scheduler,\n",
    "                    \"monitor\": \"val_loss\",\n",
    "                    \"interval\": \"epoch\",\n",
    "                    \"frequency\": 1,\n",
    "                },\n",
    "            }\n",
    "        else:\n",
    "            return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**üîπ –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?**\n",
    "1. `FCN-ResNet50` –∏–∑ `torchvision`:\n",
    "\n",
    "* –ú—ã –±–µ—Ä–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–π `FCN-ResNet50`.\n",
    "* –¢–∞–∫ –∂–µ –º–æ–∂–µ–º –Ω–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è.\n",
    "* –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –ø–µ—Ä–µ–¥–µ–ª—ã–≤–∞–µ–º –¥–ª—è `num_classes` (21)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "2. `JaccardIndex` –∏–∑ `torchmetrics`:\n",
    "\n",
    "* –ë–µ—Ä—ë–º `JaccardIndex` –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ `IoU` - –º–µ—Ç—Ä–∏–∫–∞ –≤ –∑–∞–¥–∞—á–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "* –ê–∫–∫—É–º—É–ª–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫—É –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ, –ø–æ—Ç–æ–º —Å—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–∞–Ω—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ–π —ç–ø–æ—Ö–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "3. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ `ClearML`:\n",
    "\n",
    "* –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∫–∏\n",
    "* `train_loss`, `val_loss`\n",
    "* `train_iou`, `val_iou`\n",
    "* –§–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: –≤—Ö–æ–¥–Ω–æ–µ, –º–∞—Å–∫–∞ Ground Truth, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–∞—Å–∫–∞.\n",
    "* –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ `_log_images` –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å, –∫–∞–∫ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Å—Ä–∞–≤–Ω–∏–≤–∞—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–∞—Å–∫–∏ —Å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –º–∞—Å–∫–∞–º–∏. –≠—Ç–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏, –∞ —Ç–∞–∫–∂–µ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è.\n",
    "* –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ `on_validation_epoch_end` —Å–ª—É–∂–∏—Ç –¥–ª—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
      "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n",
      "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
      "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n",
      "Train dataset size: 1464 samples\n",
      "Validation dataset size: 1449 samples\n",
      "Model Architecture: {'backbone': 'resnet50', 'head': 'FCN', 'pretrained': True, 'num_classes': 21}\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–∏\n",
    "train_loader, val_loader = get_dataloaders(config[\"batch_size\"])\n",
    "model = SegmentationModel(config)\n",
    "\n",
    "# ‚úÖ Callbacks (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏, –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ LR)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"val_iou\",\n",
    "        filename=\"fcn-resnet50-voc-{epoch:02d}-{val_iou:.3f}\",\n",
    "        save_top_k=2,\n",
    "        mode=\"max\",\n",
    "        save_last=True,\n",
    "    ),\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å\n",
    "seed_everything(42)\n",
    "trainer = Trainer(\n",
    "    max_epochs=config[\"num_epochs\"],\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # devices=\"auto\",\n",
    "    callbacks=callbacks,\n",
    "    log_every_n_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type                   | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | model         | FCN                    | 35.3 M | train\n",
      "1 | train_iou     | MulticlassJaccardIndex | 0      | train\n",
      "2 | val_iou       | MulticlassJaccardIndex | 0      | train\n",
      "3 | val_class_iou | MulticlassJaccardIndex | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "35.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "35.3 M    Total params\n",
      "141.289   Total estimated model params size (MB)\n",
      "165       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45212e276d84b9ab4f9d8512b9b048b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f123dc1ad206440ea022037c05e22152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396f4fbb75904fbd94be8bd8b1d4198b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc934749e224461877722706f3e7350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3485484f5942d3bb13522c2ec2a87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c54f76cd744913ac254c7f248ea778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88f7dcba63d4335a476ba7628178a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4cbd51a8f14d70bbdf6b6bb20f7fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd404b30cda344bc95416590cbe5d85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f32a5bd43684608abf7911830904c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85962c8834304d3ea0da34454cd85fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ‚úÖ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ –ù–µ –∑–∞–±—ã–≤–∞–µ–º –∑–∞–∫—Ä—ã—Ç—å —Ç–∞—Å–∫\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.get_output_log_web_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å—ç–º–ø–ª—ã (–≤–∫–ª–∞–¥–∫–∞ `debug`)\n",
    "\n",
    "<img src='../images/seg3.png'>\n",
    "–í–∏–¥–∏–º, —á—Ç–æ –º–æ–¥–µ–ª—å –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –æ–±—É—á–∞–µ—Ç—Å—è.\n",
    "\n",
    "### –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è (–≤–∫–ª–∞–¥–∫–∞ `scalars`)\n",
    "<img src='../images/segscal.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –¥–∞–Ω–Ω–æ–º –∫–æ–¥–µ –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–ø–æ—Ç–µ—Ä–∏ –∏ IoU), —Ç–∞–∫ –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center id=\"p6\"> üß∏ –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "–í —É—Ä–æ–∫–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ —Å–ø–æ—Å–æ–±—ã –∫–∞–∫ —Å–≤—è–∑–∫–∞ `Lightning + ClearML` –ø–æ–º–æ–∂–µ—Ç —É—Å–∫–æ—Ä–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫—É –≤ CV-–∑–∞–¥–∞—á–∞—Ö:    \n",
    "* –†–∞–∑–æ–±—Ä–∞–ª–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "* –§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–≥–æ –±—ç–∫–±–æ–Ω–∞\n",
    "* –ü–æ–Ω—è–ª–∏ –∫–∞–∫ –ª—É—á—à–µ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å –∫–æ–¥ –¥–ª—è –∑–∞–¥–∞—á–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "* –í –î–ó –ø–æ–ø—Ä–∞–∫—Ç–∏–∫—É–µ–º—Å—è –æ–±—É—á–∞—Ç—å GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "–°–≤—è–∑–∫–∞ `Lightning + ClearML` –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω–æ–π –¥–ª—è –ª—é–±–æ–π –∑–∞–¥–∞—á–∏ –≤ CV-–¥–æ–º–µ–Ω–µ, –æ—Å–æ–±–µ–Ω–Ω–æ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Å–µ—Ç–æ–∫ –Ω–∞ —É–¥–∞–ª—ë–Ω–Ω–æ–π –º–∞—à–∏–Ω–µ –∏ –≤ –∫–æ–º–∞–Ω–¥–µ. <br>\n",
    "–û—Å–æ–±–µ–Ω–Ω–æ —Å–∏–ª—å–Ω–æ –≤—ã —Å–º–æ–∂–µ—Ç–µ –ø—Ä–æ—á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å –≤—Å—é –º–æ—â—å —Å–≤—è–∑–∫–∏, –µ—Å–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–∞–∫—Ç–∏–∫—É –ø–æ –æ–±—É—á–µ–Ω–∏—é `GAN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
