{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <h1> üß∂ –°–≤—è–∑–∫–∞ `Lightning` + `ClearML` –≤ –∑–∞–¥–∞—á–∞—Ö NLP. üî§</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ –Ω–æ—É—Ç–±—É–∫–∞\n",
    "<img src='../images/nlp.webp' align=\"right\" width=\"508\" height=\"428\" >\n",
    "<br>\n",
    "\n",
    "<p><font size=\"3\" face=\"Arial\" font-size=\"large\"><ul type=\"square\">\n",
    "    \n",
    "<li><a href=\"#p1\">ü§î –ó–∞—á–µ–º –Ω—É–∂–µ–Ω Trainer?</a></li>\n",
    "<li><a href=\"#p2\">ü§π‚Äç‚ôÄÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Trainer</a></li>\n",
    "<li><a href=\"#p7\">üî´ Model, Trainer & 2 smoking CallBacks üî´</a></li>\n",
    "<li><a href=\"#p3\">üìè Torchmetrics - —É–¥–æ–±–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –ª—é–±—ã–º –º–µ—Ç—Ä–∏–∫–∞–º! üìê</a></li>\n",
    "<li><a href=\"#p4\">üìè TorchMetrics –≤ PyTorch Lightning ‚ö°</a></li>\n",
    "<li><a href=\"#p5\">üéö Tuner - –ø–æ–¥–±–∏—Ä–∞–µ–º –∏–¥–µ–∞–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã! </a></li>\n",
    "<li><a href=\"#p6\">üß∏ –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚úÖ </a></li>\n",
    "\n",
    "\n",
    "    \n",
    "</ul></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßë‚Äçüéì –¢–µ–ø–µ—Ä—å —Ä–∞–∑–±–µ—Ä–µ–º —Å–≤—è–∑–∫—É **PyTorch Lightning** + **ClearML**, –æ–±–ª–µ–≥—á–∞—é—â—É—é –∂–∏–∑–Ω—å –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —Ç–µ–∫—Å—Ç–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**ClearML** –ª–µ–≥–∫–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å **PyTorch Lightning**, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ª–æ–≥–∏—Ä—É—è –º–æ–¥–µ–ª–∏ PyTorch, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ. –í—Å–µ, —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å, —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–≤–µ —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞ –≤ –≤–∞—à —Å–∫—Ä–∏–ø—Ç **PyTorch Lightning**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "```python\n",
    "from clearml import Task\n",
    "\n",
    "Task = Task.init(task_name=\"<task_name>\", project_name=\"<project_name>\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "–í–æ—Ç –∏ –≤—Å—ë! –≠—Ç–æ —Å–æ–∑–¥–∞–µ—Ç —Ç–∞—Å–∫  **ClearML**, –∫–æ—Ç–æ—Ä—ã–π —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç:\n",
    "* –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –∏ –Ω–µ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n",
    "* –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã\n",
    "* –ú–æ–¥–µ–ª–∏ PyTorch\n",
    "* –ü–∞—Ä–∞–º–µ—Ç—Ä—ã, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º—ã–µ `LightningCLI`\n",
    "* –í—Å—ë, —á—Ç–æ –º—ã –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ TensorBoard\n",
    "* –í–µ—Å—å –≤—ã—Ö–æ–¥ –∫–æ–Ω—Å–æ–ª–∏\n",
    "* –û–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ —Å–≤–µ–¥–µ–Ω–∏—è –æ –º–∞—à–∏–Ω–µ, –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, –¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Ç. –¥.\n",
    "* –ò –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"p1\">  ü§î –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–≤—è–∑–∫—É –≤ –¥–µ–ª–µ!</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install clearml tensorboard -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from lightning import (\n",
    "    LightningDataModule,\n",
    "    LightningModule,\n",
    "    Trainer\n",
    ")\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from clearml import Task\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–≤–æ–¥–∏–º –∫–ª—é—á–∏ ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–≤–µ–¥–∏—Ç–µ API Access —Ç–æ–∫–µ–Ω:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "–í–≤–µ–¥–∏—Ç–µ API Secret —Ç–æ–∫–µ–Ω:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "# –í–≤–µ–¥–∏—Ç–µ –ø–æ–æ—á–µ—Ä—ë–¥–Ω–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∫–ª—é—á–∏ –≤ –ø–æ—è–≤–∏–≤—à–µ–º—Å—è –æ–∫–Ω–µ (–∫–æ–¥ –∏–∑–º–µ–Ω—è—Ç—å –Ω–µ –Ω—É–∂–Ω–æ)\n",
    "access_key = getpass(prompt=\"–í–≤–µ–¥–∏—Ç–µ API Access —Ç–æ–∫–µ–Ω: \")\n",
    "secret_key = getpass(prompt=\"–í–≤–µ–¥–∏—Ç–µ API Secret —Ç–æ–∫–µ–Ω: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#  –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ–∏ api-–∫–ª—é—á–∏\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "\n",
    "%env CLEARML_API_ACCESS_KEY=$access_key\n",
    "%env CLEARML_API_SECRET_KEY=$secret_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –≤–æ–∑—å–º—ë–º –¥–∞—Ç–∞—Å–µ—Ç AG NEWS, –≤ –∫–æ—Ç–æ—Ä–æ–º —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º. –ò –Ω–∞—Ç—Ä–µ–Ω–∏—Ä—É–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç–µ–º–∞—Ç–∏–∫—É –Ω–æ–≤–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                                text  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv'\n",
    "news = pd.read_csv(url, names=['label', 'title', 'text'])\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "3    30000\n",
       "4    30000\n",
       "2    30000\n",
       "1    30000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"World\", \"Sports\", \"Business\", \"Sci/Tec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> –°–æ–∑–¥–∞—ë–º Dataset –∏ Datamodule </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, csv_file, vocab=None, tokenizer=None):\n",
    "        self.data = pd.read_csv(csv_file, names=['label', 'title', 'text'])\n",
    "        self.tokenizer = tokenizer or (lambda x: x.split())\n",
    "        self.vocab = vocab or self.build_vocab()\n",
    "\n",
    "    def build_vocab(self):\n",
    "        '''\n",
    "        –°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Ç–æ–∫–µ–Ω–æ–≤ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏, –Ω–∞—á–∏–Ω–∞—è —Å \"<unk>\" (0) –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤. \n",
    "        –ú–µ—Ç–æ–¥ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ —Ç–µ–∫—Å—Ç–∞–º –≤ self.data['text'], —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –∏—Ö –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏, \n",
    "        —Ä–∞–≤–Ω—ã–º–∏ —Ç–µ–∫—É—â–µ–º—É —Ä–∞–∑–º–µ—Ä—É —Å–ª–æ–≤–∞—Ä—è.\n",
    "\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "            dict: –°–ª–æ–≤–∞—Ä—å —Ç–æ–∫–µ–Ω–æ–≤ —Å –∏—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏.\n",
    "        ''' \n",
    "    \n",
    "        vocab = {\"<unk>\": 0}\n",
    "        for text in self.data['text']:\n",
    "            for token in self.tokenizer(text):\n",
    "                if token not in vocab:\n",
    "                    vocab[token] = len(vocab)\n",
    "        return vocab\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        return torch.tensor([self.vocab.get(token, self.vocab[\"<unk>\"]) for token in self.tokenizer(text)], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.data.iloc[idx]['label'] - 1\n",
    "        text = self.data.iloc[idx]['text']\n",
    "        encoded_text = self.encode_text(text)\n",
    "        return label, encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataModule(LightningDataModule):\n",
    "    def __init__(self, train_csv, test_csv, batch_size=16, tokenizer=None):\n",
    "        super().__init__()\n",
    "        self.train_csv = train_csv\n",
    "        self.test_csv = test_csv\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer or (lambda x: x.split())\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = TextDataset(self.train_csv, tokenizer=self.tokenizer)\n",
    "        self.test_dataset = TextDataset(self.test_csv, vocab=self.train_dataset.vocab, tokenizer=self.tokenizer)\n",
    "\n",
    "        self.vocab = self.train_dataset.vocab\n",
    "        self.num_classes = len(set(self.train_dataset.data['label']))\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        labels, texts = zip(*batch)\n",
    "        offsets = torch.tensor([0] + [len(text) for text in texts[:-1]]).cumsum(dim=0)\n",
    "        texts = torch.cat(texts)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        return texts, offsets, labels\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> –ü–∏—à–µ–º –∫–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ–ª–∏ –≤ LightningModule\n",
    "\n",
    "–í –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π —Å—Ç—ç–ø –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ —Ç–µ–Ω–∑–æ—Ä–±–æ—Ä–¥, —á—Ç–æ–±—ã –æ–Ω–∏ –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∏—Å—å –≤ ClearML - –º–æ–∂–Ω–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å–ª–µ–¥–∏—Ç—å –∫–∞–∫ –º–æ–¥–µ–ª—å \"—É–º–Ω–µ–µ—Ç\", –≥–ª—è–¥—è –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSentimentModel(LightningModule):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class, learning_rate=1.0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        text, offsets, labels = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        text, offsets, labels = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(1) == labels).float().mean()\n",
    "\n",
    "        # Log validation loss and accuracy\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "        # Log text predictions to TensorBoard\n",
    "        predictions = outputs.argmax(1)\n",
    "        for i in range(min(5, len(labels))):\n",
    "            self.logger.experiment.add_text(\n",
    "                \"val_predictions\",\n",
    "                f'''Text: {text[i]}; \n",
    "                Prediction: {classes[predictions[i].item() - 1]}; \n",
    "                True Label: {classes[labels[i].item() - 1]}''',\n",
    "                self.global_step\n",
    "            )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=e668e53af0994119a75add7f9d6cd953\n",
      "2025-01-21 00:00:37,713 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/651ec2987cb34c0c9613bda5583f55e9/experiments/e668e53af0994119a75add7f9d6cd953/output/log\n"
     ]
    }
   ],
   "source": [
    "# Initialize ClearML task\n",
    "task = Task.init(project_name=\"TextClassification\", task_name=\"AG_NEWS Text Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "train_csv = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\"\n",
    "test_csv = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv\"\n",
    "batch_size = 48\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–¥–µ–ª–∞—Ç—å –∫–ª–∞—Å—Å –∫–æ–Ω—Ñ–∏–≥–∞ –∏ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –Ω–∏–∂–µ\n",
    "configuration_dict = {'number_of_epochs': 2, 'batch_size': 48, 'ngrams': 2, 'base_lr': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataModule\n",
    "data_module = TextDataModule(train_csv, test_csv, batch_size=batch_size)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(data_module.vocab)\n",
    "embed_dim = 32\n",
    "num_class = data_module.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number_of_epochs': 2, 'batch_size': 48, 'ngrams': 2, 'base_lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# –î–æ–±–∞–≤–∏—Ç—å –≤ –∫–ª–∞—Å—Å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å\n",
    "configuration_dict = task.connect(configuration_dict)  # enabling configuration override by clearml\n",
    "print(configuration_dict)  # printing actual configuration (after override in remote mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Model\n",
    "model = TextSentimentModel(vocab_size, embed_dim, num_class, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jovyan/venvs/sinara/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "# Logger and Trainer\n",
    "logger = TensorBoardLogger(\"./lightning_logs\", name=\"text_classification\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    logger=[logger],\n",
    "    accelerator=\"cpu\",\n",
    "    #devices=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | embedding | EmbeddingBag     | 5.0 M  | train\n",
      "1 | fc        | Linear           | 132    | train\n",
      "2 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.974    Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/venvs/sinara/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/jovyan/venvs/sinara/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f2bc0f64e24fb488e2c879abaa3216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, vocab, tokenizer):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = torch.tensor([vocab.get(token, vocab[\"<unk>\"]) for token in tokenizer(text)], dtype=torch.long)\n",
    "        offsets = torch.tensor([0])\n",
    "        output = model(tokens, offsets)\n",
    "        prediction = output.argmax(1).item()\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor.split() missing 1 required positional argument: 'split_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m random_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data_module\u001b[38;5;241m.\u001b[39mtest_dataset), (\u001b[38;5;241m1\u001b[39m,))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      3\u001b[0m example_label, example_text \u001b[38;5;241m=\u001b[39m data_module\u001b[38;5;241m.\u001b[39mtest_dataset[random_idx]\n\u001b[0;32m----> 4\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(text, model, vocab, tokenizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([vocab\u001b[38;5;241m.\u001b[39mget(token, vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m      5\u001b[0m     offsets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(tokens, offsets)\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mTextDataModule.__init__.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_csv \u001b[38;5;241m=\u001b[39m test_csv\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m tokenizer \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor.split() missing 1 required positional argument: 'split_size'"
     ]
    }
   ],
   "source": [
    "# Load a random example from the test dataset\n",
    "random_idx = torch.randint(0, len(data_module.test_dataset), (1,)).item()\n",
    "example_label, example_text = data_module.test_dataset[random_idx]\n",
    "predicted_label = predict(example_text, model, data_module.vocab, data_module.tokenizer)\n",
    "\n",
    "print(f\"Text: {example_text}\")\n",
    "print(f\"True Label: {example_label}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ä–∞–∑–≤–∏—Ç–∏–µ:\n",
    "–ú–æ–∂–Ω–æ –ø—Ä–∏–ª–µ–ø–∏—Ç—å, —á—Ç–æ-—Ç–æ –∏–∑ —Ç–æ—Ä—á–º–µ—Ç—Ä–∏–∫—Å, –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤\n",
    "–î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ + –∫–æ–ª–±—ç–∫–∏ –∫ —Ç—Ä–µ–Ω–µ—Ä—É"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ UI –æ—Ç ClearML –∏ —Å–º–æ—Ç—Ä–∏–º –∞–Ω–∞–ª–∏—Ç–∏–∫—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
