{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <h1> üß∂ –°–≤—è–∑–∫–∞ `Lightning` + `ClearML` –≤ –∑–∞–¥–∞—á–∞—Ö NLP. üî§</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ –Ω–æ—É—Ç–±—É–∫–∞\n",
    "<img src='../images/nlp.webp' align=\"right\" width=\"508\" height=\"428\" >\n",
    "<br>\n",
    "\n",
    "<p><font size=\"3\" face=\"Arial\" font-size=\"large\"><ul type=\"square\">\n",
    "    \n",
    "<li><a href=\"#p1\">üßê –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–≤—è–∑–∫—É –≤ –¥–µ–ª–µ!</a></li>\n",
    "<li><a href=\"#p2\">‚òùÔ∏è 1-–π —Å–ø–æ—Å–æ–±: –ª–æ–≥–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –∫–æ–Ω—Å–æ–ª—å</a></li>\n",
    "<li><a href=\"#p7\">‚úåÔ∏è 2-–π —Å–ø–æ—Å–æ–±: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ TensorBoardLogger</a></li>\n",
    "<li><a href=\"#p5\">üéö Finetuning —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –ø–æ–¥ —Å–≤–æ—é –∑–∞–¥–∞—á—É </a></li>\n",
    "<li><a href=\"#p6\">üß∏ –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚úÖ </a></li>\n",
    "\n",
    "\n",
    "    \n",
    "</ul></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> üßë‚Äçüéì –†–∞–∑–±–µ—Ä–µ–º —Å–≤—è–∑–∫—É **PyTorch Lightning** + **ClearML**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**ClearML** –ª–µ–≥–∫–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å **PyTorch Lightning**, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ª–æ–≥–∏—Ä—É—è –º–æ–¥–µ–ª–∏ PyTorch, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ. –≠—Ç–∞ —Å–≤—è–∑–∫–∞ –∑–Ω–∞—á–∏–º–æ —É–ø—Ä–æ—â–∞–µ—Ç —Ä–∞–±–æ—Ç—É –≤ –∑–∞–¥–∞—á–∞—Ö —Å —Ç–µ–∫—Å—Ç–∞–º–∏. \n",
    "\n",
    "–í—Å–µ, —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å, —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–≤–µ —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞ –≤ –≤–∞—à —Å–∫—Ä–∏–ø—Ç **PyTorch Lightning**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "```python\n",
    "from clearml import Task\n",
    "\n",
    "task = Task.init(task_name=\"<task_name>\", project_name=\"<project_name>\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "ü§Ø –í–æ—Ç –∏ –≤—Å—ë! –≠—Ç–æ —Å–æ–∑–¥–∞–µ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ **ClearML**, –∫–æ—Ç–æ—Ä—ã–π —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç:\n",
    "\n",
    "* –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –∏ –Ω–µ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n",
    "* –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã\n",
    "* –ú–æ–¥–µ–ª–∏ PyTorch\n",
    "* –ü–∞—Ä–∞–º–µ—Ç—Ä—ã, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º—ã–µ `LightningCLI`\n",
    "* –í—Å—ë, —á—Ç–æ –º—ã –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ TensorBoard\n",
    "* –í–µ—Å—å –≤—ã—Ö–æ–¥ –∫–æ–Ω—Å–æ–ª–∏\n",
    "* –û–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ —Å–≤–µ–¥–µ–Ω–∏—è –æ –º–∞—à–∏–Ω–µ, –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, –¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Ç. –¥.\n",
    "* –ò –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"p1\">  üßê –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–≤—è–∑–∫—É –≤ –¥–µ–ª–µ!</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install clearml tensorboard datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import asdict, dataclass\n",
    "\n",
    "from lightning import LightningDataModule, LightningModule, Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from clearml import Task, Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–≤–æ–¥–∏–º –∫–ª—é—á–∏ ClearML —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã https://app.clear.ml/settings/workspace-configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–≤–µ–¥–∏—Ç–µ API Access —Ç–æ–∫–µ–Ω:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "–í–≤–µ–¥–∏—Ç–µ API Secret —Ç–æ–∫–µ–Ω:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "# –í–≤–µ–¥–∏—Ç–µ –ø–æ–æ—á–µ—Ä—ë–¥–Ω–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∫–ª—é—á–∏ –≤ –ø–æ—è–≤–∏–≤—à–µ–º—Å—è –æ–∫–Ω–µ (–∫–æ–¥ –∏–∑–º–µ–Ω—è—Ç—å –Ω–µ –Ω—É–∂–Ω–æ)\n",
    "access_key = getpass(prompt=\"–í–≤–µ–¥–∏—Ç–µ API Access —Ç–æ–∫–µ–Ω: \")\n",
    "secret_key = getpass(prompt=\"–í–≤–µ–¥–∏—Ç–µ API Secret —Ç–æ–∫–µ–Ω: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#  –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ–∏ api-–∫–ª—é—á–∏\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "\n",
    "%env CLEARML_API_ACCESS_KEY=$access_key\n",
    "%env CLEARML_API_SECRET_KEY=$secret_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "–î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –≤–æ–∑—å–º—ë–º –¥–∞—Ç–∞—Å–µ—Ç `AG NEWS`, –≤ –∫–æ—Ç–æ—Ä–æ–º —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º. –ò –Ω–∞—Ç—Ä–µ–Ω–∏—Ä—É–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç–µ–º–∞—Ç–∏–∫—É –Ω–æ–≤–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                                text  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv'\n",
    "news = pd.read_csv(url, names=['label', 'title', 'text'])\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "3    30000\n",
       "4    30000\n",
       "2    30000\n",
       "1    30000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"World\", \"Sports\", \"Sci/Tec\", \"Business\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> –°–æ–∑–¥–∞—ë–º Dataset –∏ Datamodule </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, csv_file, vocab=None, tokenizer=None):\n",
    "        self.data = pd.read_csv(csv_file, names=['label', 'title', 'text'])\n",
    "        self.tokenizer = tokenizer or (lambda x: x.split())\n",
    "        self.vocab = vocab or self.build_vocab()\n",
    "\n",
    "    def build_vocab(self):\n",
    "        '''\n",
    "        –°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Ç–æ–∫–µ–Ω–æ–≤ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏, –Ω–∞—á–∏–Ω–∞—è —Å \"<unk>\" (0) –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤. \n",
    "        –ú–µ—Ç–æ–¥ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ —Ç–µ–∫—Å—Ç–∞–º –≤ self.data['text'], —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –∏—Ö –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏, \n",
    "        —Ä–∞–≤–Ω—ã–º–∏ —Ç–µ–∫—É—â–µ–º—É —Ä–∞–∑–º–µ—Ä—É —Å–ª–æ–≤–∞—Ä—è.\n",
    "\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "            dict: –°–ª–æ–≤–∞—Ä—å —Ç–æ–∫–µ–Ω–æ–≤ —Å –∏—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏.\n",
    "        ''' \n",
    "    \n",
    "        vocab = {\"<unk>\": 0}\n",
    "        for text in self.data['text']:\n",
    "            for token in self.tokenizer(text):\n",
    "                if token not in vocab:\n",
    "                    vocab[token] = len(vocab)\n",
    "        return vocab\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        return torch.tensor([self.vocab.get(token, self.vocab[\"<unk>\"]) for token in self.tokenizer(text)], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.data.iloc[idx]['label'] - 1\n",
    "        text = self.data.iloc[idx]['text']\n",
    "        encoded_text = self.encode_text(text)\n",
    "        return label, encoded_text, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataModule(LightningDataModule):\n",
    "    def __init__(self, train_csv, test_csv, batch_size=16, tokenizer=None):\n",
    "        super().__init__()\n",
    "        self.train_csv = train_csv\n",
    "        self.test_csv = test_csv\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer or (lambda x: x.split())\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = TextDataset(self.train_csv, tokenizer=self.tokenizer)\n",
    "        self.test_dataset = TextDataset(self.test_csv, vocab=self.train_dataset.vocab, tokenizer=self.tokenizer)\n",
    "\n",
    "        self.vocab = self.train_dataset.vocab\n",
    "        self.num_classes = len(set(self.train_dataset.data['label']))\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        labels, texts, origs = zip(*batch)\n",
    "        offsets = torch.tensor([0] + [len(text) for text in texts[:-1]]).cumsum(dim=0)\n",
    "        texts = torch.cat(texts)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        return texts, offsets, labels, origs\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"p2\"> ‚òùÔ∏è 1-–π —Å–ø–æ—Å–æ–±: –ª–æ–≥–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –∫–æ–Ω—Å–æ–ª—å\n",
    "\n",
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "\n",
    "–£–¥–æ–±–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∏—Ç–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ - –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞ –∫–∞–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö –º–æ–¥–µ–ª—å —Å–∏–ª—å–Ω–µ–µ –æ—à–∏–±–∞–µ—Ç—Å—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "**–î–ª—è —ç—Ç–æ–≥–æ:** –í –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π —Å—Ç—ç–ø –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π, —á—Ç–æ–±—ã –æ–Ω–∏ –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∏—Å—å –≤ `ClearML` - –º–æ–∂–Ω–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å–ª–µ–¥–∏—Ç—å –∫–∞–∫ –º–æ–¥–µ–ª—å \"—É–º–Ω–µ–µ—Ç\", –≥–ª—è–¥—è –Ω–∞ –µ—ë –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.\n",
    "\n",
    "\n",
    "–≠—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–≤—É–º—è —Å–ø–æ—Å–æ–±–∞–º–∏:\n",
    "* —á–µ—Ä–µ–∑ –∫–æ–Ω—Å–æ–ª—å, –∏—Å–ø–æ–ª—å–∑—É—è `logger ClearML`\n",
    "* —á–µ—Ä–µ–∑ `debug samples`, –∏—Å–ø–æ–ª—å–∑—É—è `TensorBoardLogger`\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∏—à–µ–º –∫–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ–ª–∏ –≤ LightningModule\n",
    "class TextSentimentModel(LightningModule):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class, learning_rate=1.0, logger=None, batch_size=48):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loggs = logger # –¥–æ–±–∞–≤–ª—è–µ–º –≤–Ω–µ—à–Ω–∏–π –ª–æ–≥–≥–µ—Ä\n",
    "        self.batch_size = batch_size\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        text, offsets, labels, origs = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        text, offsets, labels, origs = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(1) == labels).float().mean()\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º validation loss and accuracy –≤ –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, batch_size=self.batch_size)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, batch_size=self.batch_size)\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—ç–º–ø–ª—ã\n",
    "        if logger and batch_idx == 0:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞\n",
    "            predictions = outputs.argmax(1)\n",
    "            print(f\"Val_predictions for epoch {self.current_epoch}:\")\n",
    "            for i in range(min(5, len(labels))):\n",
    "                    self.loggs.report_text(\n",
    "                    f'''Text: {origs[i]}; \n",
    "                    Prediction: {classes[predictions[i].item() - 1]}; \n",
    "                    True Label: {classes[labels[i].item() - 1]}'''\n",
    "                )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'TextClassification',\n",
       " 'task_name': 'AG_NEWS Text Classification',\n",
       " 'train_csv': 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv',\n",
       " 'test_csv': 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv',\n",
       " 'batch_size': 48,\n",
       " 'learning_rate': 0.01,\n",
       " 'seed': 2024,\n",
       " 'device': 'cpu',\n",
       " 'embed_dim': 32,\n",
       " 'epochs': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞–¥–∏–º –∫–æ–Ω—Ñ–∏–≥\n",
    "@dataclass\n",
    "class CFG:\n",
    "    project_name: str = \"TextClassification\"\n",
    "    task_name: str = \"AG_NEWS Text Classification\"\n",
    "    train_csv: str = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\"\n",
    "    test_csv: str = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv\"\n",
    "    batch_size: int = 48\n",
    "    learning_rate: float = 0.01\n",
    "    seed: int = 2024\n",
    "    device: str = 'cpu'  #\"cuda\"\n",
    "    embed_dim: int = 32\n",
    "    epochs: int = 3\n",
    "\n",
    "# –ß—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ç–µ–∫—É—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –ø–µ—Ä–µ–Ω–µ—Å—ë–º –µ—ë –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "cfg = CFG()\n",
    "configuration_dict = asdict(cfg)\n",
    "configuration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=488c8c3a113c4126bec2618c53ebc2bb\n",
      "2025-02-12 21:53:14,851 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/651ec2987cb34c0c9613bda5583f55e9/experiments/488c8c3a113c4126bec2618c53ebc2bb/output/log\n"
     ]
    }
   ],
   "source": [
    "# Initialize ClearML task\n",
    "task = Task.init(project_name=cfg.project_name, task_name=cfg.task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger.current_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º DataModule\n",
    "data_module = TextDataModule(cfg.train_csv, cfg.test_csv, batch_size=cfg.batch_size)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project_name': 'TextClassification', 'task_name': 'AG_NEWS Text Classification', 'train_csv': 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv', 'test_csv': 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv', 'batch_size': 48, 'learning_rate': 0.01, 'seed': 2024, 'device': 'cpu', 'embed_dim': 32, 'epochs': 3}\n"
     ]
    }
   ],
   "source": [
    "# –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥ –≤ ClearML\n",
    "cfg.vocab_size = len(data_module.vocab)\n",
    "cfg.num_class = data_module.num_classes\n",
    "configuration_dict = task.connect(asdict(cfg))\n",
    "print(configuration_dict)  # printing actual configuration (after override in remote mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "model = TextSentimentModel(cfg.vocab_size, cfg.embed_dim, cfg.num_class, cfg.learning_rate, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    accelerator=cfg.device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "–ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É, –≤–∏–¥–∏–º, —á—Ç–æ –∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É –≤ –∫–æ–Ω—Å–æ–ª—å –ø–∏—à—É—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–∞—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | embedding | EmbeddingBag     | 5.0 M  | train\n",
      "1 | fc        | Linear           | 132    | train\n",
      "2 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.974    Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954363ac2ea24c55adcf6ceafd7e81ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8356fa5f4c44b38b99d911748effa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82d7dacbdf1455d8e71d0291c5f0d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_predictions for epoch 0:\n",
      "Text: ----- NASHVILLE, Tennessee (Ticker) - The Nashville Predators signed defenseman Ryan Suter, their first-round pick in the 2003 draft, on Thursday.; \n",
      "                    Prediction: Sports; \n",
      "                    True Label: World\n",
      "Text: Strong international sales growth and solid U.S. comps propel the company's stock to its highest price ever.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sports\n",
      "Text: The Russian president puts some blame on his international critics -- and supports president Bush; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Business\n",
      "Text: The Net needs a new layer of abilities that will deal with imminent problems of capacity, security and reliability, Intel's CTO says.; \n",
      "                    Prediction: Sports; \n",
      "                    True Label: Sci/Tec\n",
      "Text: BOSTON - Computer viruses and worms will have to share the stage with a new challenger for the attention of attendees at a conference of antivirus researchers: spam e-mail.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9501eb274d2345438a4fb1f975067963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_predictions for epoch 1:\n",
      "Text: ----- NASHVILLE, Tennessee (Ticker) - The Nashville Predators signed defenseman Ryan Suter, their first-round pick in the 2003 draft, on Thursday.; \n",
      "                    Prediction: Sports; \n",
      "                    True Label: World\n",
      "Text: Strong international sales growth and solid U.S. comps propel the company's stock to its highest price ever.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sports\n",
      "Text: The Russian president puts some blame on his international critics -- and supports president Bush; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Business\n",
      "Text: The Net needs a new layer of abilities that will deal with imminent problems of capacity, security and reliability, Intel's CTO says.; \n",
      "                    Prediction: Sports; \n",
      "                    True Label: Sci/Tec\n",
      "Text: BOSTON - Computer viruses and worms will have to share the stage with a new challenger for the attention of attendees at a conference of antivirus researchers: spam e-mail.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6e87db7d36459ab8061692907dd414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_predictions for epoch 2:\n",
      "Text: ----- NASHVILLE, Tennessee (Ticker) - The Nashville Predators signed defenseman Ryan Suter, their first-round pick in the 2003 draft, on Thursday.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: World\n",
      "Text: Strong international sales growth and solid U.S. comps propel the company's stock to its highest price ever.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sports\n",
      "Text: The Russian president puts some blame on his international critics -- and supports president Bush; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Business\n",
      "Text: The Net needs a new layer of abilities that will deal with imminent problems of capacity, security and reliability, Intel's CTO says.; \n",
      "                    Prediction: Sports; \n",
      "                    True Label: Sci/Tec\n",
      "Text: BOSTON - Computer viruses and worms will have to share the stage with a new challenger for the attention of attendees at a conference of antivirus researchers: spam e-mail.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "–ü—Ä–æ–≤–µ—Ä–∏–º –∫–∞–∫ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ –∏–∑ —Ç–µ—Å—Ç–∞!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, vocab, tokenizer):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = torch.tensor([vocab.get(token, vocab[\"<unk>\"]) for token in tokenizer(text)], dtype=torch.long)\n",
    "        offsets = torch.tensor([0])\n",
    "        output = model(tokens, offsets)\n",
    "        prediction = output.argmax(1).item()\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Javy Lopez drives in four runs, Daniel Cabrera becomes the first rookie to win 10 games this season, and the Orioles hold Tampa Bay to two hits in an 8-0 victory Wednesday night.\n",
      "True Label: 1\n",
      "Predicted Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Load a random example from the test dataset\n",
    "random_idx = torch.randint(0, len(data_module.test_dataset), (1,)).item()\n",
    "example_label, example_text, orig = data_module.test_dataset[random_idx]\n",
    "predicted_label = predict(orig, model, data_module.vocab, data_module.tokenizer)\n",
    "\n",
    "print(f\"Text: {orig}\")\n",
    "print(f\"True Label: {example_label}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–µ –∑–∞–±—ã–≤–∞–µ–º –∑–∞–≤–µ—Ä—à–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "## <center> –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ UI –æ—Ç ClearML\n",
    "\n",
    "C–º–æ—Ç—Ä–∏–º –∫–∞–∫ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–ª–∏—Å—å –Ω–∞—à–∏ —Å—ç–º–ø–ª—ã - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "<img src='../images/clnlp.png'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center id=\"p7\"> ‚úåÔ∏è 2-–π —Å–ø–æ—Å–æ–±: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ `TensorBoardLogger`\n",
    "\n",
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "* –ë–æ–ª–µ–µ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –∫–æ–¥\n",
    "* –ú–µ–Ω—å—à–µ –º—É—Å–æ—Ä–∞ –≤ –∫–æ–Ω—Å–æ–ª–∏\n",
    "* –õ–µ–≥—á–µ –Ω–∞–π—Ç–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å—ç–º–ø–ª—ã –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π –≤–∫–ª–∞–¥–∫–µ\n",
    "* –ù–µ –Ω—É–∂–Ω–æ —Ä–∞–∑–≥—Ä–µ–±–∞—Ç—å –≤—Å—é –∫–æ–Ω—Å–æ–ª—å –∏ –∏—Å–∫–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å—Ä–µ–¥–∏ –¥—Ä—É–≥–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–æ–Ω—Å–æ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSentimentModel(LightningModule):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class, learning_rate=1.0, batch_size=48):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        text, offsets, labels, origs = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        text, offsets, labels, origs = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(1) == labels).float().mean()\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º validation loss and accuracy –≤ –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, batch_size=self.batch_size)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, batch_size=self.batch_size)\n",
    "\n",
    "        # # –õ–æ–≥–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—ç–º–ø–ª—ã\n",
    "        if batch_idx == 0:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞\n",
    "            predictions = outputs.argmax(1)\n",
    "            for i in range(min(5, len(labels))):\n",
    "                    self.logger.experiment.add_text(\n",
    "                \"val_predictions\",\n",
    "                f'''Text: {origs[i]}; \n",
    "                Prediction: {classes[predictions[i].item() - 1]}; \n",
    "                True Label: {classes[labels[i].item() - 1]}''',\n",
    "                self.global_step\n",
    "            )\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=c9b914e959bb4a398592e2f0bea89352\n",
      "ClearML results page: https://app.clear.ml/projects/651ec2987cb34c0c9613bda5583f55e9/experiments/c9b914e959bb4a398592e2f0bea89352/output/log\n"
     ]
    }
   ],
   "source": [
    "# Initialize ClearML task\n",
    "task = Task.init(project_name=cfg.project_name, \n",
    "                 task_name=cfg.task_name, \n",
    "                 auto_connect_frameworks={'tensorboard': True}) # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π TensorBoard –≤ ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextSentimentModel(cfg.vocab_size, cfg.embed_dim, cfg.num_class, cfg.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sinarian/venvs/sinara/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: PossibleUserWarning:\n",
      "\n",
      "GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# –õ–æ–≥–≥–µ—Ä –∏ —Ç—Ä–µ–Ω–µ—Ä\n",
    "logger = TensorBoardLogger(\"./lightning_logs\", name=\"text_classification\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    logger=[logger],\n",
    "    accelerator=cfg.device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | embedding | EmbeddingBag     | 5.0 M  | train\n",
      "1 | fc        | Linear           | 132    | train\n",
      "2 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.974    Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e722d9a9821147b49f9152a8c6426925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f17c6f42ee430383ee72fb58a7e347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9febea7f4d9e4d4a84b9da23760ed32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7ee187524f4b7290085117025e9cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705cc4be8d6440f484cc1998a068283d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–µ –∑–∞–±—ã–≤–∞–µ–º –∑–∞–≤–µ—Ä—à–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≤–∫–ª–∞–¥–∫—É `debug samples`\n",
    "\n",
    "<img src='../images/debnlp.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –∫–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å—ç–º–ø–ª\n",
    "(–æ—Ç–∫—Ä–æ–µ—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –æ–∫–Ω–µ, –µ—Å–ª–∏ –∫–ª–∏–∫–Ω—É—Ç—å –ø–æ –Ω–µ–º—É)\n",
    "\n",
    "<img src='../images/smpnlp.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"p5\"> üéö Finetuning —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –ø–æ–¥ —Å–≤–æ—é –∑–∞–¥–∞—á—É </center>\n",
    "\n",
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –µ—â—ë –æ–¥–∏–Ω –ø–æ–ø—É–ª—è—Ä–Ω—ã–π —é–∑–∫–µ–π—Å - –¥–æ–æ–±—É—á–µ–Ω–∏–µ (—Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥) —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –ø–æ–¥ —Å–≤–æ—é –∑–∞–¥–∞—á—É –≤ —Å–≤—è–∑–∫–µ `Lightning + ClearML`!\n",
    "\n",
    "–í–æ–∑—å–º—ë–º –¥–∞—Ç–∞—Å–µ—Ç `IMBD` —Å –æ—Ç–∑—ã–≤–∞–º–∏ –æ —Ñ–∏–ª—å–º–∞—Ö –∏ –¥–æ–æ–±—É—á–∏–º `DistilBert` –ø–æ–¥ –∑–∞–¥–∞—á—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –æ—Ç–∑—ã–≤–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataModule(LightningDataModule):\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\", batch_size=16):\n",
    "        super().__init__()\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç IMDB\n",
    "        load_dataset(\"imdb\")\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        dataset = load_dataset(\"imdb\")\n",
    "        self.train_data = dataset[\"train\"]\n",
    "        self.test_data = dataset[\"test\"]\n",
    "\n",
    "        def tokenize_function(examples):\n",
    "            return self.tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "        self.train_data = self.train_data.map(tokenize_function, batched=True)\n",
    "        self.test_data = self.test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "        self.train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\", \"text\"])\n",
    "        self.test_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\", \"text\"])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertClassifier(LightningModule):\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\", learning_rate=2e-5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.model(input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = self.loss_fn(outputs, batch[\"label\"])\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = self.loss_fn(outputs, batch[\"label\"])\n",
    "        acc = (outputs.argmax(1) == batch[\"label\"]).float().mean()\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        \n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ TensorBoard\n",
    "        if batch_idx == 0:\n",
    "            for i in range(min(5, len(batch[\"label\"]))):\n",
    "                self.logger.experiment.add_text(\n",
    "                    \"val_predictions\",\n",
    "                    f'''Text: {batch['text'][i]}; \n",
    "                    Prediction: {outputs.argmax(1)[i].item()}; \n",
    "                    True Label: {batch['label'][i].item()}''',\n",
    "                    self.global_step\n",
    "                )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'TextClassification',\n",
       " 'task_name': 'Fine-tune DistilBERT',\n",
       " 'batch_size': 32,\n",
       " 'learning_rate': 2e-05,\n",
       " 'seed': 2024,\n",
       " 'device': 'cuda',\n",
       " 'epochs': 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    project_name: str = \"TextClassification\"\n",
    "    task_name: str = \"Fine-tune DistilBERT\"\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 2e-5\n",
    "    seed: int = 2024\n",
    "    device: str = 'cuda'  #\"cuda\"\n",
    "    epochs: int = 3\n",
    "\n",
    "# –ß—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ç–µ–∫—É—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –ø–µ—Ä–µ–Ω–µ—Å—ë–º –µ—ë –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "cfg = CFG()\n",
    "configuration_dict = asdict(cfg)\n",
    "configuration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=60fc42b4e08a4532af10aa834f9cef9a\n",
      "2025-02-12 23:40:48,025 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/651ec2987cb34c0c9613bda5583f55e9/experiments/60fc42b4e08a4532af10aa834f9cef9a/output/log\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ –≤ ClearML\n",
    "task = Task.init(project_name=cfg.project_name, \n",
    "                 task_name=cfg.task_name, \n",
    "                 auto_connect_frameworks={'tensorboard': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476197434ba841239a4073e9970b1534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962a91521e5449a58afbc0793f3f0d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_module = IMDBDataModule(batch_size=cfg.batch_size)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "model = DistilBertClassifier(learning_rate=cfg.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"distilbert_imdb\")\n",
    "trainer = Trainer(max_epochs=cfg.epochs, \n",
    "                  accelerator=cfg.device, \n",
    "                  logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333b837af3624bbaa00ee9b61599330d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e750bb8c374e4c812061acb80d362c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/sinarian/venvs/sinara/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning:\n",
      "\n",
      "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\n",
      "\n",
      "  | Name    | Type                                | Params | Mode \n",
      "------------------------------------------------------------------------\n",
      "0 | model   | DistilBertForSequenceClassification | 67.0 M | eval \n",
      "1 | loss_fn | CrossEntropyLoss                    | 0      | train\n",
      "------------------------------------------------------------------------\n",
      "67.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "67.0 M    Total params\n",
      "267.820   Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "96        Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf165467aa3a4e20858febbe322a5e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f713d804434e9893800dac4c8eb71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadef26726f94f41b4c0a0cad096fcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48897b134ca4e30ae6eb8434b12ae6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e718fddb5a5e4091a31eccbc34530619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "–ü—Ä–æ–≤–µ—Ä–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–π —Ñ—Ä–∞–∑–µ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "        output = model(tokens[\"input_ids\"], tokens[\"attention_mask\"])\n",
    "        prediction = output.argmax(1).item()\n",
    "        return \"Positive\" if prediction == 1 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This movie was absolutely fantastic! The story, the acting, everything was perfect.\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"This movie was absolutely fantastic! The story, the acting, everything was perfect.\"\n",
    "predicted_label = predict(sample_text, model, data_module.tokenizer)\n",
    "\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Predicted Sentiment: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–ú–æ–∂–µ–º –ø–µ—Ä–µ–π—Ç–∏ –≤ `WebUI ClearML` –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –ª–æ–≥–∏ –∏ `debug samples`.\n",
    "\n",
    "<img src='../images/debtr.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center id=\"p6\"> üß∏ –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–í —É—Ä–æ–∫–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ —Å–ø–æ—Å–æ–±—ã –∫–∞–∫ —Å–≤—è–∑–∫–∞ `Lightning + ClearML` –ø–æ–º–æ–∂–µ—Ç —É—Å–∫–æ—Ä–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫—É NLP-–∑–∞–¥–∞—á:\n",
    "* –ü–æ–ø—Ä–æ–±–æ–≤–∞–ª–∏ 2 —Å–ø–æ—Å–æ–±–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤\n",
    "* –ü—Ä–∏–º–µ–Ω–∏–ª–∏ —Å–≤—è–∑–∫—É –≤ –∑–∞–¥–∞—á–µ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞\n",
    "* –í –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–º –∑–∞–¥–∞–Ω–∏–∏ –ø–æ–ø—Ä–∞–∫—Ç–∏–∫—É–µ—Ç–µ—Å—å –≤ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–µ LLM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "–°–≤—è–∑–∫–∞ `Lightning + ClearML` –¥–µ–ª–∞–µ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É NLP-–º–æ–¥–µ–ª–µ–π –±—ã—Å—Ç—Ä–µ–µ –∏ —É–¥–æ–±–Ω–µ–µ:\n",
    "\n",
    "* `Lightning` = —É–ø—Ä–æ—â—ë–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n",
    "* `ClearML` = –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "üí° –ï—Å–ª–∏ –≤—ã —Ä–∞–±–æ—Ç–∞–µ—Ç–µ —Å NLP –∏ PyTorch ‚Äî —ç—Ç–æ—Ç —Å—Ç–µ–∫ —É—Å–∫–æ—Ä–∏—Ç –≤–∞—à –ø–∞–π–ø–ª–∞–π–Ω –∏ —É–ø—Ä–æ—Å—Ç–∏—Ç –æ—Ç–ª–∞–¥–∫—É! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
