{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <h1> üß∂ –°–≤—è–∑–∫–∞ `Lightning` + `ClearML` –≤ NLP. üî§</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ –Ω–æ—É—Ç–±—É–∫–∞\n",
    "<img src='../images/clearml_py_lit.jpg' align=\"right\" width=\"508\" height=\"428\" >\n",
    "<br>\n",
    "\n",
    "<p><font size=\"3\" face=\"Arial\" font-size=\"large\"><ul type=\"square\">\n",
    "    \n",
    "<li><a href=\"#p1\">üßê –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–≤—è–∑–∫—É –≤ –¥–µ–ª–µ!</a></li>\n",
    "<li><a href=\"#p2\">‚òùÔ∏è 1-–π —Å–ø–æ—Å–æ–±: –ª–æ–≥–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –∫–æ–Ω—Å–æ–ª—å</a></li>\n",
    "<li><a href=\"#p7\">‚úåÔ∏è 2-–π —Å–ø–æ—Å–æ–±: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ TensorBoardLogger</a></li>\n",
    "<li><a href=\"#p5\">üéö Finetuning —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –ø–æ–¥ —Å–≤–æ—é –∑–∞–¥–∞—á—É </a></li>\n",
    "<li><a href=\"#p6\">üß∏ –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚úÖ </a></li>\n",
    "\n",
    "\n",
    "    \n",
    "</ul></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> üßë‚Äçüéì –†–∞–∑–±–µ—Ä–µ–º —Å–≤—è–∑–∫—É **PyTorch Lightning** + **ClearML**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**ClearML** –ª–µ–≥–∫–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å **PyTorch Lightning**, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ª–æ–≥–∏—Ä—É—è –º–æ–¥–µ–ª–∏ PyTorch, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ. –≠—Ç–∞ —Å–≤—è–∑–∫–∞ –∑–Ω–∞—á–∏–º–æ —É–ø—Ä–æ—â–∞–µ—Ç —Ä–∞–±–æ—Ç—É –≤ –∑–∞–¥–∞—á–∞—Ö —Å —Ç–µ–∫—Å—Ç–∞–º–∏. \n",
    "\n",
    "–ü—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –¥–≤–µ –ø—Ä–∏–≤—ã—á–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞ –≤ –≤–∞—à —Å–∫—Ä–∏–ø—Ç **PyTorch Lightning**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "```python\n",
    "from clearml import Task\n",
    "\n",
    "task = Task.init(task_name=\"<task_name>\", project_name=\"<project_name>\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "ü§Ø –í–æ—Ç –∏ –≤—Å—ë! –≠—Ç–æ —Å–æ–∑–¥–∞–µ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –≤ **ClearML**, –∫–æ—Ç–æ—Ä—ã–π —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç:\n",
    "\n",
    "* –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –∏ –Ω–µ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n",
    "* –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã\n",
    "* –ú–æ–¥–µ–ª–∏ PyTorch\n",
    "* –ü–∞—Ä–∞–º–µ—Ç—Ä—ã, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º—ã–µ `LightningCLI`\n",
    "* –í—Å—ë, —á—Ç–æ –º—ã –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ TensorBoard\n",
    "* –í–µ—Å—å –≤—ã—Ö–æ–¥ –∫–æ–Ω—Å–æ–ª–∏\n",
    "* –û–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ —Å–≤–µ–¥–µ–Ω–∏—è –æ –º–∞—à–∏–Ω–µ, –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, –¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Ç. –¥.\n",
    "* –ò –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <center> üîë –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ –∫–ª—é—á–µ–π "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install clearml tensorboard datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml import Task, Logger\n",
    "\n",
    "from lightning import LightningDataModule, LightningModule, Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import asdict, dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–≤–æ–¥–∏–º –∫–ª—é—á–∏ ClearML —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã https://app.clear.ml/settings/workspace-configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "\n",
    "# # –í–≤–µ–¥–∏—Ç–µ –ø–æ–æ—á–µ—Ä—ë–¥–Ω–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∫–ª—é—á–∏ –≤ –ø–æ—è–≤–∏–≤—à–µ–º—Å—è –æ–∫–Ω–µ (–∫–æ–¥ –∏–∑–º–µ–Ω—è—Ç—å –Ω–µ –Ω—É–∂–Ω–æ)\n",
    "# access_key = getpass(prompt=\"–í–≤–µ–¥–∏—Ç–µ API Access —Ç–æ–∫–µ–Ω: \")\n",
    "# secret_key = getpass(prompt=\"–í–≤–µ–¥–∏—Ç–µ API Secret —Ç–æ–∫–µ–Ω: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# #  –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–≤–æ–∏ api-–∫–ª—é—á–∏\n",
    "# %env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "# %env CLEARML_API_HOST=https://api.clear.ml\n",
    "# %env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "\n",
    "# %env CLEARML_API_ACCESS_KEY=$access_key\n",
    "# %env CLEARML_API_SECRET_KEY=$secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=UR73VVAQC4EUA46EA09ZMIM08YT21P\n",
      "env: CLEARML_API_SECRET_KEY=ZC2NeA8YNAxcEfepGgjZ9RTI0yJNx1E24R3W3dqYx4P5LWTRFOWuwCQhHB2pSwCxMvg\n"
     ]
    }
   ],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=UR73VVAQC4EUA46EA09ZMIM08YT21P\n",
    "%env CLEARML_API_SECRET_KEY=ZC2NeA8YNAxcEfepGgjZ9RTI0yJNx1E24R3W3dqYx4P5LWTRFOWuwCQhHB2pSwCxMvg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> üóû –†–∞–∑–±–µ—Ä–µ–º —Å–≤—è–∑–∫—É –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "\n",
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "–î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –≤–æ–∑—å–º—ë–º –¥–∞—Ç–∞—Å–µ—Ç `AG NEWS`, –≤ –∫–æ—Ç–æ—Ä–æ–º —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º. –ò –Ω–∞—Ç—Ä–µ–Ω–∏—Ä—É–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç–µ–º–∞—Ç–∏–∫—É –Ω–æ–≤–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              title  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "\n",
       "                                                text  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\"\n",
    "news = pd.read_csv(url, names=[\"label\", \"title\", \"text\"])\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "3    30000\n",
       "4    30000\n",
       "2    30000\n",
       "1    30000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"World\", \"Sports\", \"Sci/Tec\", \"Business\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> üöÇ –°–æ–∑–¥–∞—ë–º –∫–ª–∞—Å—Å—ã Dataset –∏ Datamodule </center>\n",
    "\n",
    "–ó–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å—Ç–∞—Ç–µ–π –≤—ã—à–µ, –ª–µ–≥–∫–æ —Å–æ–±—Ä–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∫–ª–∞—Å—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, csv_file, vocab=None, tokenizer=None):\n",
    "        self.data = pd.read_csv(csv_file, names=[\"label\", \"title\", \"text\"])\n",
    "        self.tokenizer = tokenizer or (lambda x: x.split())\n",
    "        self.vocab = vocab or self.build_vocab()\n",
    "\n",
    "    def build_vocab(self):\n",
    "        \"\"\"\n",
    "        –°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Ç–æ–∫–µ–Ω–æ–≤ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏, –Ω–∞—á–∏–Ω–∞—è —Å \"<unk>\" (0) –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "        –ú–µ—Ç–æ–¥ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ —Ç–µ–∫—Å—Ç–∞–º –≤ self.data['text'], —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –∏—Ö –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏,\n",
    "        —Ä–∞–≤–Ω—ã–º–∏ —Ç–µ–∫—É—â–µ–º—É —Ä–∞–∑–º–µ—Ä—É —Å–ª–æ–≤–∞—Ä—è.\n",
    "\n",
    "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "            dict: –°–ª–æ–≤–∞—Ä—å —Ç–æ–∫–µ–Ω–æ–≤ —Å –∏—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞–º–∏.\n",
    "        \"\"\"\n",
    "\n",
    "        vocab = {\"<unk>\": 0}\n",
    "        for text in self.data[\"text\"]:\n",
    "            for token in self.tokenizer(text):\n",
    "                if token not in vocab:\n",
    "                    vocab[token] = len(vocab)\n",
    "        return vocab\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        return torch.tensor(\n",
    "            [\n",
    "                self.vocab.get(token, self.vocab[\"<unk>\"])\n",
    "                for token in self.tokenizer(text)\n",
    "            ],\n",
    "            dtype=torch.long,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.data.iloc[idx][\"label\"] - 1\n",
    "        text = self.data.iloc[idx][\"text\"]\n",
    "        encoded_text = self.encode_text(text)\n",
    "        return label, encoded_text, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataModule(LightningDataModule):\n",
    "    def __init__(self, train_csv, test_csv, batch_size=16, tokenizer=None):\n",
    "        super().__init__()\n",
    "        self.train_csv = train_csv\n",
    "        self.test_csv = test_csv\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer or (lambda x: x.split())\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = TextDataset(self.train_csv, tokenizer=self.tokenizer)\n",
    "        self.test_dataset = TextDataset(\n",
    "            self.test_csv, vocab=self.train_dataset.vocab, tokenizer=self.tokenizer\n",
    "        )\n",
    "\n",
    "        self.vocab = self.train_dataset.vocab\n",
    "        self.num_classes = len(set(self.train_dataset.data[\"label\"]))\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        labels, texts, origs = zip(*batch)\n",
    "        offsets = torch.tensor([0] + [len(text) for text in texts[:-1]]).cumsum(dim=0)\n",
    "        texts = torch.cat(texts)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        return texts, offsets, labels, origs\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.collate_fn,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            collate_fn=self.collate_fn,\n",
    "            num_workers=4,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"p1\">  üßê –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é —Å–≤—è–∑–∫–∏ –≤ –¥–µ–ª–µ!</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "**–î–ª—è —ç—Ç–æ–≥–æ:** –í –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π —Å—Ç—ç–ø –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π, —á—Ç–æ–±—ã –æ–Ω–∏ –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∏—Å—å –≤ `ClearML`. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º –º–æ–∂–Ω–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å, –∫–∞–∫ –º–æ–¥–µ–ª—å \"—É–º–Ω–µ–µ—Ç\", –≥–ª—è–¥—è –Ω–∞ –µ—ë –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "‚úåÔ∏è –≠—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–≤—É–º—è —Å–ø–æ—Å–æ–±–∞–º–∏:\n",
    "* —á–µ—Ä–µ–∑ –∫–æ–Ω—Å–æ–ª—å, –∏—Å–ø–æ–ª—å–∑—É—è `logger ClearML` (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –≤–∫–ª–∞–¥–∫–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ `CONSOLE`)\n",
    "* —á–µ—Ä–µ–∑ `debug samples`, –∏—Å–ø–æ–ª—å–∑—É—è `TensorBoardLogger` (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –≤–∫–ª–∞–¥–∫–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ `DEBUG SAMPLES`)\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"p2\"> ‚òùÔ∏è 1-–π —Å–ø–æ—Å–æ–±: –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å\n",
    "\n",
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "–ó–∞—á–µ–º –Ω–∞–º —Ç—É—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ? –£–¥–æ–±–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∏—Ç–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ - –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–∞ –∫–∞–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö –º–æ–¥–µ–ª—å —Å–∏–ª—å–Ω–µ–µ –æ—à–∏–±–∞–µ—Ç—Å—è.\n",
    "\n",
    "–î–ª—è —ç—Ç–æ–≥–æ –º—ã –≤ –º–µ—Ç–æ–¥–µ `validation_step` –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –ª–æ–≥–≥–µ—Ä –æ—Ç **ClearML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ –ü–∏—à–µ–º –∫–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ–ª–∏ –≤ LightningModule\n",
    "class TextSentimentModel(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embed_dim,\n",
    "        num_class,\n",
    "        learning_rate=1.0,\n",
    "        logger=None,\n",
    "        batch_size=48,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.init_weights()\n",
    "\n",
    "        # —Ç–∞–∫ –∫–∞–∫ self.logger –∏ self.log –∑–∞–Ω—è—Ç—ã –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º –∫–ª–∞—Å—Å–µ, –≤–æ–∑—å–º–µ–º —Ç–∞–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ\n",
    "        self.loggs = logger  # <--------------- –¥–æ–±–∞–≤–∏–º –ª–æ–≥–≥–µ—Ä –∏–∑ –Ω–∞—à–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ ClearML\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):  \n",
    "        text, offsets, labels, origs = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):  # <--------------- –¥–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å —á–µ—Ä–µ–∑ –ª–æ–≥–≥–µ—Ä\n",
    "        text, offsets, labels, origs = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(1) == labels).float().mean()\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º validation loss and accuracy –≤ –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, batch_size=self.batch_size)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, batch_size=self.batch_size)\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—ç–º–ø–ª—ã\n",
    "        if logger and batch_idx == 0:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞\n",
    "            predictions = outputs.argmax(1)\n",
    "            print(f\"Val_predictions for epoch {self.current_epoch}:\")\n",
    "            for i in range(min(5, len(labels))):\n",
    "                # –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥—ã –ª–æ–≥–≥–µ—Ä–∞ ClearML\n",
    "                self.loggs.report_text(\n",
    "                    f\"\"\"Text: {origs[i]}; \n",
    "                    Prediction: {classes[predictions[i].item() - 1]}; \n",
    "                    True Label: {classes[labels[i].item() - 1]}\"\"\"\n",
    "                )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'TextClassification',\n",
       " 'task_name': 'AG_NEWS Text Classification',\n",
       " 'train_csv': 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv',\n",
       " 'test_csv': 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv',\n",
       " 'batch_size': 48,\n",
       " 'learning_rate': 0.01,\n",
       " 'seed': 2024,\n",
       " 'device': 'cpu',\n",
       " 'embed_dim': 32,\n",
       " 'epochs': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  ‚úÖ –°–æ–∑–¥–∞–¥–∏–º –∫–æ–Ω—Ñ–∏–≥\n",
    "@dataclass\n",
    "class CFG:\n",
    "    project_name: str = \"TextClassification\"\n",
    "    task_name: str = \"AG_NEWS Text Classification\"\n",
    "    train_csv: str = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\"\n",
    "    test_csv: str = \"https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv\"\n",
    "    batch_size: int = 48\n",
    "    learning_rate: float = 0.01\n",
    "    seed: int = 2024\n",
    "    device: str = \"cpu\"  # \"cuda\"\n",
    "    embed_dim: int = 32\n",
    "    epochs: int = 3\n",
    "\n",
    "\n",
    "# –ß—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ç–µ–∫—É—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –ø–µ—Ä–µ–Ω–µ—Å—ë–º –µ—ë –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "cfg = CFG()\n",
    "configuration_dict = asdict(cfg)\n",
    "configuration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=fb28d3451ca04ce9a94f023e1972e7f3\n",
      "2025-04-13 19:09:11,257 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/59abf2fa89ba4cf4ab73936b09c61821/experiments/fb28d3451ca04ce9a94f023e1972e7f3/output/log\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ClearML task\n",
    "task = Task.init(project_name=cfg.project_name, task_name=cfg.task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑ ClearML\n",
    "logger = Logger.current_logger() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ  –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º DataModule\n",
    "data_module = TextDataModule(cfg.train_csv, cfg.test_csv, batch_size=cfg.batch_size)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project_name': 'TextClassification', 'task_name': 'AG_NEWS Text Classification', 'train_csv': 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv', 'test_csv': 'https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv', 'batch_size': 48, 'learning_rate': 0.01, 'seed': 2024, 'device': 'cpu', 'embed_dim': 32, 'epochs': 3}\n"
     ]
    }
   ],
   "source": [
    "# –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥ –≤ ClearML\n",
    "cfg.vocab_size = len(data_module.vocab)\n",
    "cfg.num_class = data_module.num_classes\n",
    "configuration_dict = task.connect(asdict(cfg))\n",
    "\n",
    "print(configuration_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –∏ –ø–µ—Ä–µ–¥–∞–µ–º –ª–æ–≥–≥–µ—Ä\n",
    "model = TextSentimentModel(\n",
    "    cfg.vocab_size, cfg.embed_dim, cfg.num_class, cfg.learning_rate,\n",
    "    logger=logger # <--------------- –ø–µ—Ä–µ–¥–∞–µ–º –ª–æ–≥–≥–µ—Ä –≤ –∞—Ä–≥—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–¥–∞–ª–∏ –≤ –∫–ª–∞—Å—Å–µ —Å–∞–º–∏\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sinarian/venvs/sinara/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: PossibleUserWarning:\n",
      "\n",
      "GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–µ—Ä –∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ–º –ª–æ–≥–≥–µ—Ä\n",
    "trainer = Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    accelerator=cfg.device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "–ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É, –≤–∏–¥–∏–º, —á—Ç–æ –∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É –≤ –∫–æ–Ω—Å–æ–ª—å –ø–∏—à—É—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–∞—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | embedding | EmbeddingBag     | 5.0 M  | train\n",
      "1 | fc        | Linear           | 132    | train\n",
      "2 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.974    Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543cb7ae4f3d42d9995a42a64b9b47d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_predictions for epoch 0:\n",
      "Text: Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sports\n",
      "Text: SPACE.com - TORONTO, Canada -- A second\\team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already he knows what the day will bring. Lightning will strike in places he expects. Winds will pick up, moist places will dry and flames will roar.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - Southern California's smog-fighting agency went after emissions of the bovine variety Friday, adopting the nation's first rules to reduce air pollution from dairy cow manure.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sci/Tec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860010939a874fecab4adb64d9dd1b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f187020bb16943859bbe6e520e0bccf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_predictions for epoch 0:\n",
      "Text: Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.; \n",
      "                    Prediction: Sports; \n",
      "                    True Label: Sports\n",
      "Text: SPACE.com - TORONTO, Canada -- A second\\team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already he knows what the day will bring. Lightning will strike in places he expects. Winds will pick up, moist places will dry and flames will roar.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - Southern California's smog-fighting agency went after emissions of the bovine variety Friday, adopting the nation's first rules to reduce air pollution from dairy cow manure.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sci/Tec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1c3e602659495a8e9fbef62d489bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_predictions for epoch 1:\n",
      "Text: Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.; \n",
      "                    Prediction: Sports; \n",
      "                    True Label: Sports\n",
      "Text: SPACE.com - TORONTO, Canada -- A second\\team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket.; \n",
      "                    Prediction: Sports; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already he knows what the day will bring. Lightning will strike in places he expects. Winds will pick up, moist places will dry and flames will roar.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - Southern California's smog-fighting agency went after emissions of the bovine variety Friday, adopting the nation's first rules to reduce air pollution from dairy cow manure.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sci/Tec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584727d1c95547d4b36995e806521e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_predictions for epoch 2:\n",
      "Text: Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.; \n",
      "                    Prediction: Sports; \n",
      "                    True Label: Sports\n",
      "Text: SPACE.com - TORONTO, Canada -- A second\\team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for\\privately funded suborbital space flight, has officially announced the first\\launch date for its manned rocket.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already he knows what the day will bring. Lightning will strike in places he expects. Winds will pick up, moist places will dry and flames will roar.; \n",
      "                    Prediction: Business; \n",
      "                    True Label: Sci/Tec\n",
      "Text: AP - Southern California's smog-fighting agency went after emissions of the bovine variety Friday, adopting the nation's first rules to reduce air pollution from dairy cow manure.; \n",
      "                    Prediction: Sci/Tec; \n",
      "                    True Label: Sci/Tec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "–ü—Ä–æ–≤–µ—Ä–∏–º –∫–∞–∫ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ –∏–∑ —Ç–µ—Å—Ç–∞!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, vocab, tokenizer):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = torch.tensor(\n",
    "            [vocab.get(token, vocab[\"<unk>\"]) for token in tokenizer(text)],\n",
    "            dtype=torch.long,\n",
    "        )\n",
    "        offsets = torch.tensor([0])\n",
    "        output = model(tokens, offsets)\n",
    "        prediction = output.argmax(1).item()\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Javy Lopez drives in four runs, Daniel Cabrera becomes the first rookie to win 10 games this season, and the Orioles hold Tampa Bay to two hits in an 8-0 victory Wednesday night.\n",
      "True Label: 1\n",
      "Predicted Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Load a random example from the test dataset\n",
    "random_idx = torch.randint(0, len(data_module.test_dataset), (1,)).item()\n",
    "example_label, example_text, orig = data_module.test_dataset[random_idx]\n",
    "predicted_label = predict(orig, model, data_module.vocab, data_module.tokenizer)\n",
    "\n",
    "print(f\"Text: {orig}\")\n",
    "print(f\"True Label: {example_label}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–µ –∑–∞–±—ã–≤–∞–µ–º –∑–∞–≤–µ—Ä—à–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://app.clear.ml/projects/59abf2fa89ba4cf4ab73936b09c61821/experiments/fb28d3451ca04ce9a94f023e1972e7f3/output/log'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.get_output_log_web_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "‚úÖ –í–∏–¥–∏–º, —á—Ç–æ –≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ. –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –≤–µ—Ä–Ω—ã–π!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "## <center> üèÉ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ UI –æ—Ç ClearML\n",
    "\n",
    "C–º–æ—Ç—Ä–∏–º –∫–∞–∫ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–ª–∏—Å—å –Ω–∞—à–∏ —Å—ç–º–ø–ª—ã - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "<div class=\"alert alert-info\"> \n",
    "\n",
    "<img src='../images/clnlp.png'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**–ü–ª—é—Å—ã —Ç–∞–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞:**\n",
    "* –ë—ã—Å—Ç—Ä–æ –∏ –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ —Å–∫—Ä–∏–ø—Ç\n",
    "* –ù–µ –Ω—É–∂–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ª–æ–≥–≥–µ—Ä—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**–ú–∏–Ω—É—Å—ã:**\n",
    "* –ï—Å–ª–∏ –º–Ω–æ–≥–æ —ç–ø–æ—Ö –∏ –º–Ω–æ–≥–æ –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, –¥–æ–ª–≥–æ —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è –≤ –ø—Ä–æ—Å—Ç—ã–Ω–µ –ª–æ–≥–æ–≤\n",
    "* –¢–∞–∫ –∂–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã–≤–æ–¥—ã –≤ –∫–æ–Ω—Å–æ–ª—å –∏–ª–∏ –æ—à–∏–±–∫–∏ –º–æ–≥—É—Ç —Å–º–µ—à–∏–≤–∞—Ç—å—Å—è —Å –æ—Ç–ª–∞–¥–æ—á–Ω—ã–º–∏ –æ–±—Ä–∞–∑—Ü–∞–º–∏, –±—É–¥–µ—Ç –µ—â—ë —Ç—Ä—É–¥–Ω–µ–µ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –≤ –ª–æ–≥–∞—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"p7\"> ‚úåÔ∏è 2-–π —Å–ø–æ—Å–æ–±: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ `TensorBoardLogger`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "* –ë–æ–ª–µ–µ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –∫–æ–¥\n",
    "* –ú–µ–Ω—å—à–µ –º—É—Å–æ—Ä–∞ –≤ –∫–æ–Ω—Å–æ–ª–∏\n",
    "* –õ–µ–≥—á–µ –Ω–∞–π—Ç–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å—ç–º–ø–ª—ã –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π –≤–∫–ª–∞–¥–∫–µ\n",
    "* –ù–µ –Ω—É–∂–Ω–æ —Ä–∞–∑–≥—Ä–µ–±–∞—Ç—å –≤—Å—é –∫–æ–Ω—Å–æ–ª—å –∏ –∏—Å–∫–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å—Ä–µ–¥–∏ –¥—Ä—É–≥–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–æ–Ω—Å–æ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSentimentModel(LightningModule):\n",
    "    def __init__(\n",
    "        self, vocab_size, embed_dim, num_class, learning_rate=1.0, batch_size=48\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        text, offsets, labels, origs = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):  # <--------------- –¥–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å —á–µ—Ä–µ–∑ self.logger \n",
    "        text, offsets, labels, origs = batch\n",
    "        outputs = self.forward(text, offsets)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        acc = (outputs.argmax(1) == labels).float().mean()\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º validation loss and accuracy –≤ –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, batch_size=self.batch_size)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, batch_size=self.batch_size)\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Å—ç–º–ø–ª—ã\n",
    "        if batch_idx == 0:  # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞\n",
    "            predictions = outputs.argmax(1)\n",
    "            for i in range(min(5, len(labels))):\n",
    "                # –∑–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥–≥–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π —É–∫–∞–∂–µ–º –≤ Trainer\n",
    "                self.logger.experiment.add_text(  # –¥–æ—Å—Ç—É–ø –∫ –Ω–µ–º—É –ø–æ–ª—É—á–∞–µ–º —á–µ—Ä–µ–∑ self.logger\n",
    "                    \"val_predictions\",\n",
    "                    f\"\"\"Text: {origs[i]}; \n",
    "                Prediction: {classes[predictions[i].item() - 1]}; \n",
    "                True Label: {classes[labels[i].item() - 1]}\"\"\",\n",
    "                    self.global_step,\n",
    "                )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.task_name =  \"AG_NEWS Text Classification v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=c2563e47a5c042409496808514f25887\n",
      "ClearML results page: https://app.clear.ml/projects/59abf2fa89ba4cf4ab73936b09c61821/experiments/c2563e47a5c042409496808514f25887/output/log\n"
     ]
    }
   ],
   "source": [
    "# Initialize ClearML task\n",
    "task = Task.init(\n",
    "    project_name=cfg.project_name,\n",
    "    task_name=cfg.task_name,\n",
    "    auto_connect_frameworks={\"tensorboard\": True},\n",
    ")  # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π TensorBoard –≤ ClearML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ–º –ª–æ–≥–≥–µ—Ä\n",
    "model = TextSentimentModel(\n",
    "    cfg.vocab_size, cfg.embed_dim, cfg.num_class, cfg.learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/sinarian/venvs/sinara/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: PossibleUserWarning:\n",
      "\n",
      "GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–≥–µ—Ä, —Ç—Ä–µ–Ω–µ—Ä –∏ —Å—Ä–∞–∑—É –ø–µ—Ä–µ–¥–∞–µ–º –≤ —Ç—Ä–µ–Ω–µ—Ä –ª–æ–≥–≥–µ—Ä\n",
    "logger = TensorBoardLogger(\"./lightning_logs\", name=\"text_classification\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    logger=[logger],  # <--------------- –ø–µ—Ä–µ–¥–∞–µ–º –ª–æ–≥–≥–µ—Ä –≤ –∞—Ä–≥—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤ —Ç—Ä–µ–Ω–µ—Ä–µ\n",
    "    accelerator=cfg.device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | embedding | EmbeddingBag     | 5.0 M  | train\n",
      "1 | fc        | Linear           | 132    | train\n",
      "2 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "5.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.0 M     Total params\n",
      "19.974    Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648c749308c546f395d1eb874fdf15e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4db169ac86d4fdab129f42871d5761e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181a9557527b406d84e20f0e742c7cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e71f6b824e4342b865e5ac1dca1db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e023c475e794800b86213a8800d6d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–µ –∑–∞–±—ã–≤–∞–µ–º –∑–∞–≤–µ—Ä—à–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://app.clear.ml/projects/59abf2fa89ba4cf4ab73936b09c61821/experiments/c2563e47a5c042409496808514f25887/output/log'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.get_output_log_web_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≤–∫–ª–∞–¥–∫—É `DEBUG SAMPLES`\n",
    "\n",
    "<img src='../images/debnlp.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –∫–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å—ç–º–ø–ª\n",
    "(–æ—Ç–∫—Ä–æ–µ—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –æ–∫–Ω–µ, –µ—Å–ª–∏ –∫–ª–∏–∫–Ω—É—Ç—å –ø–æ –Ω–µ–º—É)\n",
    "\n",
    "<img src='../images/smpnlp.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"p5\"> üéö Finetuning (–¥–æ–æ–±—É—á–µ–Ω–∏–µ) —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –ø–æ–¥ —Å–≤–æ—é –∑–∞–¥–∞—á—É </center>\n",
    "\n",
    "<div class=\"alert alert-info\"> \n",
    "    \n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –µ—â—ë –æ–¥–∏–Ω –ø–æ–ø—É–ª—è—Ä–Ω—ã–π —é–∑–∫–µ–π—Å - –¥–æ–æ–±—É—á–µ–Ω–∏–µ (—Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥) —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –ø–æ–¥ —Å–≤–æ—é –∑–∞–¥–∞—á—É –≤ —Å–≤—è–∑–∫–µ `Lightning + ClearML`!\n",
    "\n",
    "–í–æ–∑—å–º—ë–º –¥–∞—Ç–∞—Å–µ—Ç `IMBD` —Å –æ—Ç–∑—ã–≤–∞–º–∏ –æ —Ñ–∏–ª—å–º–∞—Ö –∏ –¥–æ–æ–±—É—á–∏–º `DistilBert` –ø–æ–¥ –∑–∞–¥–∞—á—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –æ—Ç–∑—ã–≤–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∏—à–µ–º LightningDataModule\n",
    "class IMDBDataModule(LightningDataModule):\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\", batch_size=16):\n",
    "        super().__init__()\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç IMDB\n",
    "        load_dataset(\"imdb\")\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        dataset = load_dataset(\"imdb\")\n",
    "        self.train_data = dataset[\"train\"]\n",
    "        self.test_data = dataset[\"test\"]\n",
    "\n",
    "        def tokenize_function(examples):\n",
    "            return self.tokenizer(\n",
    "                examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512\n",
    "            )\n",
    "\n",
    "        self.train_data = self.train_data.map(tokenize_function, batched=True)\n",
    "        self.test_data = self.test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "        self.train_data.set_format(\n",
    "            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\", \"text\"]\n",
    "        )\n",
    "        self.test_data.set_format(\n",
    "            type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\", \"text\"]\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=4\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∏—à–µ–º LightningModule\n",
    "class DistilBertClassifier(LightningModule):\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\", learning_rate=2e-5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=2\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.model(input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = self.loss_fn(outputs, batch[\"label\"])\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(batch[\"input_ids\"], batch[\"attention_mask\"])\n",
    "        loss = self.loss_fn(outputs, batch[\"label\"])\n",
    "        acc = (outputs.argmax(1) == batch[\"label\"]).float().mean()\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ TensorBoard\n",
    "        if batch_idx == 0:\n",
    "            for i in range(min(5, len(batch[\"label\"]))):\n",
    "                self.logger.experiment.add_text(\n",
    "                    \"val_predictions\",\n",
    "                    f\"\"\"Text: {batch['text'][i]}; \n",
    "                    Prediction: {outputs.argmax(1)[i].item()}; \n",
    "                    True Label: {batch['label'][i].item()}\"\"\",\n",
    "                    self.global_step,\n",
    "                )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'TextClassification',\n",
       " 'task_name': 'Fine-tune DistilBERT',\n",
       " 'batch_size': 32,\n",
       " 'learning_rate': 2e-05,\n",
       " 'seed': 2024,\n",
       " 'device': 'cuda',\n",
       " 'epochs': 3}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    project_name: str = \"TextClassification\"\n",
    "    task_name: str = \"Fine-tune DistilBERT\"\n",
    "    batch_size: int = 32\n",
    "    learning_rate: float = 2e-5\n",
    "    seed: int = 2024\n",
    "    device: str = \"cuda\"  # \"cuda\"\n",
    "    epochs: int = 3\n",
    "\n",
    "\n",
    "# –ß—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Ç–µ–∫—É—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞, –ø–µ—Ä–µ–Ω–µ—Å—ë–º –µ—ë –≤ —Å–ª–æ–≤–∞—Ä—å\n",
    "cfg = CFG()\n",
    "configuration_dict = asdict(cfg)\n",
    "configuration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=6561991b55224b61989cb3789b3ca6b5\n",
      "ClearML results page: https://app.clear.ml/projects/59abf2fa89ba4cf4ab73936b09c61821/experiments/6561991b55224b61989cb3789b3ca6b5/output/log\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ –≤ ClearML\n",
    "task = Task.init(\n",
    "    project_name=cfg.project_name,\n",
    "    task_name=cfg.task_name,\n",
    "    auto_connect_frameworks={\"tensorboard\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a96011a24c24859bb50e0eab0be5dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c4ada8eab74791b308b3ad5ea070ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4acdae1466b5404db3ff67ca275f0490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c831b1ada5428f961c57e86b086cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973120578e0f44ed9065bab794239209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc6de343d3b4561a43be766fbf1a39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41898e696e314555a2a02942b74be059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1e182409874d2ea55f4e0bac9775dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc06498f90c94ee9ae65980c1b25bf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8f53edaf8049a8a786a675112a52a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4e0e061d254c2e8dd20dcc5809e35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b140c3e42614dd3afd8a27e2ecd2e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a96a2ea1f984e16bbfcf5f335f7a151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e866918c96429fb734d1c035ebff51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_module = IMDBDataModule(batch_size=cfg.batch_size)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "model = DistilBertClassifier(learning_rate=cfg.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"distilbert_imdb\")\n",
    "\n",
    "trainer = Trainer(max_epochs=cfg.epochs,\n",
    "                  accelerator=cfg.device,\n",
    "                  logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"> \n",
    "\n",
    "–û—Ç–ª–∏—á–Ω–æ, –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–∞–ª–µ–µ –ø—Ä–æ–≤–µ—Ä–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–π —Ñ—Ä–∞–∑–µ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,\n",
    "        )\n",
    "        output = model(tokens[\"input_ids\"], tokens[\"attention_mask\"])\n",
    "        prediction = output.argmax(1).item()\n",
    "        return \"Positive\" if prediction == 1 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This movie was absolutely fantastic! The story, the acting, everything was perfect.\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"This movie was absolutely fantastic! The story, the acting, everything was perfect.\"\n",
    "predicted_label = predict(sample_text, model, data_module.tokenizer)\n",
    "\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Predicted Sentiment: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–ú–æ–∂–µ–º –ø–µ—Ä–µ–π—Ç–∏ –≤ `WebUI ClearML` –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –ª–æ–≥–∏ –≤ `DEBUG SAMPLES`.\n",
    "\n",
    "<img src='../images/debtr.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center id=\"p6\"> üß∏ –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–í —É—Ä–æ–∫–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ —Å–ø–æ—Å–æ–±—ã –∫–∞–∫ —Å–≤—è–∑–∫–∞ `Lightning + ClearML` –ø–æ–º–æ–∂–µ—Ç —É—Å–∫–æ—Ä–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫—É NLP-–∑–∞–¥–∞—á:\n",
    "* –ü–æ–ø—Ä–æ–±–æ–≤–∞–ª–∏ 2 —Å–ø–æ—Å–æ–±–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤\n",
    "* –ü—Ä–∏–º–µ–Ω–∏–ª–∏ —Å–≤—è–∑–∫—É –≤ –∑–∞–¥–∞—á–µ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "–°–≤—è–∑–∫–∞ `Lightning + ClearML` –¥–µ–ª–∞–µ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É NLP-–º–æ–¥–µ–ª–µ–π –±—ã—Å—Ç—Ä–µ–µ –∏ —É–¥–æ–±–Ω–µ–µ:\n",
    "\n",
    "* `Lightning` = —É–ø—Ä–æ—â—ë–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n",
    "* `ClearML` = –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "* –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `debug samples` –ø—Ä–æ—â–µ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—Ç—á–µ—Ç–∞\n",
    "\n",
    "üí° –ï—Å–ª–∏ –≤—ã —Ä–∞–±–æ—Ç–∞–µ—Ç–µ —Å NLP –∏ PyTorch ‚Äî —ç—Ç–æ—Ç —Å—Ç–µ–∫ —É—Å–∫–æ—Ä–∏—Ç –≤–∞—à –ø–∞–π–ø–ª–∞–π–Ω –∏ —É–ø—Ä–æ—Å—Ç–∏—Ç –æ—Ç–ª–∞–¥–∫—É! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
